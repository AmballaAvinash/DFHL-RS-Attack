{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "209a4dd9-14d1-450b-8762-db36db43ef07",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/work/pi_dhruveshpate_umass_edu/aamballa_umass_edu/.conda/envs/DFME/lib/python3.9/site-packages/kornia/feature/lightglue.py:44: FutureWarning: `torch.cuda.amp.custom_fwd(args...)` is deprecated. Please use `torch.amp.custom_fwd(args..., device_type='cuda')` instead.\n",
      "  @torch.cuda.amp.custom_fwd(cast_inputs=torch.float32)\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import torch\n",
    "import random\n",
    "import warnings\n",
    "import numpy as np\n",
    "import torchvision\n",
    "import torch.nn as nn\n",
    "from tqdm import tqdm\n",
    "from copy import deepcopy\n",
    "from kornia import augmentation\n",
    "import torch.nn.functional as F\n",
    "import matplotlib.pyplot as plt\n",
    "from diffusers import UNet2DModel\n",
    "from datasets import load_dataset\n",
    "from torchvision import transforms\n",
    "from diffusers import DDPMScheduler\n",
    "from PIL import ImageDraw, ImageFont, Image\n",
    "from datasets import load_dataset, load_metric\n",
    "import torchvision.transforms.functional as TF\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "warnings.filterwarnings(\"ignore\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f1a83a42-7fa1-4069-a5ab-de1a26b60fbe",
   "metadata": {},
   "source": [
    "### Define Generator, Victim and Stolen"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "058833bf-736f-48ab-b1b4-20cbb202d88b",
   "metadata": {},
   "outputs": [],
   "source": [
    "class DoubleConv(nn.Module):\n",
    "    def __init__(self, in_channels, out_channels):\n",
    "        super().__init__()\n",
    "        self.conv = nn.Sequential(\n",
    "            nn.Conv2d(in_channels, out_channels, kernel_size=3, padding=1, bias=False),\n",
    "            nn.BatchNorm2d(out_channels),\n",
    "            nn.ReLU(inplace=True),\n",
    "            nn.Conv2d(out_channels, out_channels, kernel_size=3, padding=1, bias=False),\n",
    "            nn.BatchNorm2d(out_channels),\n",
    "            nn.ReLU(inplace=True)\n",
    "        )\n",
    "\n",
    "    def forward(self, x):\n",
    "        return self.conv(x)\n",
    "\n",
    "class UNet(nn.Module):\n",
    "    def __init__(self, in_channels, out_channels, features=[64, 128, 256, 512]):\n",
    "        super().__init__()\n",
    "        self.downs = nn.ModuleList()\n",
    "        self.ups = nn.ModuleList()\n",
    "        self.pool = nn.MaxPool2d(kernel_size=2, stride=2)\n",
    "\n",
    "        # Downsampling\n",
    "        for feature in features:\n",
    "            self.downs.append(DoubleConv(in_channels, feature))\n",
    "            in_channels = feature\n",
    "\n",
    "        # Upsampling\n",
    "        for feature in reversed(features):\n",
    "            self.ups.append(\n",
    "                nn.ConvTranspose2d(feature * 2, feature, kernel_size=2, stride=2)\n",
    "            )\n",
    "            self.ups.append(DoubleConv(feature * 2, feature))\n",
    "\n",
    "        self.bottleneck = DoubleConv(features[-1], features[-1] * 2)\n",
    "        self.final_conv = nn.Conv2d(features[0], out_channels, kernel_size=1)\n",
    "\n",
    "    def forward(self, x):\n",
    "        skip_connections = []\n",
    "\n",
    "        # Downsampling\n",
    "        for down in self.downs:\n",
    "            x = down(x)\n",
    "            skip_connections.append(x)\n",
    "            x = self.pool(x)\n",
    "\n",
    "        x = self.bottleneck(x)\n",
    "        skip_connections = skip_connections[::-1]\n",
    "\n",
    "        # Upsampling\n",
    "        for idx in range(0, len(self.ups), 2):\n",
    "            x = self.ups[idx](x)\n",
    "            skip_connection = skip_connections[idx // 2]\n",
    "\n",
    "            if x.shape != skip_connection.shape:\n",
    "                x = nn.functional.resize(x, size=skip_connection.shape[2:])\n",
    "\n",
    "            concat_skip = torch.cat((skip_connection, x), dim=1)\n",
    "            x = self.ups[idx + 1](concat_skip)\n",
    "\n",
    "        return self.final_conv(x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "0c002cc9-5599-440c-81a0-abe667f37c95",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_generator(args):\n",
    "    class MultiStepGenerator(nn.Module):\n",
    "        def __init__(self, args):\n",
    "            super(MultiStepGenerator, self).__init__()\n",
    "            self.unet =UNet(in_channels=args.img_c, out_channels=args.img_c)\n",
    "            self.num_timesteps = args.num_timesteps\n",
    "        \n",
    "        def forward(self, noise):\n",
    "            images = []\n",
    "            current_image = noise\n",
    "    \n",
    "            for _ in range(self.num_timesteps):\n",
    "                current_image = self.unet(current_image)\n",
    "                images.append(current_image)\n",
    "            \n",
    "            return images\n",
    "\n",
    "    return MultiStepGenerator(args).to(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "58c1448a-87e0-4758-b630-61a68a8e2a7f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# class Net(nn.Module):\n",
    "#         def __init__(self):\n",
    "#             super(Net, self).__init__()\n",
    "#             self.conv1 = nn.Conv2d(1, 32, 3, 1)\n",
    "#             self.conv2 = nn.Conv2d(32, 64, 3, 1)\n",
    "#             self.fc1 = nn.Linear(12544, 128)\n",
    "#             self.fc2 = nn.Linear(128, 10)\n",
    "    \n",
    "#         def forward(self, x):\n",
    "#             x = F.relu(self.conv1(x))\n",
    "#             x = F.relu(self.conv2(x))\n",
    "#             x = F.max_pool2d(x, 2)\n",
    "#             x = torch.flatten(x, 1)\n",
    "#             x = F.relu(self.fc1(x))\n",
    "#             x = self.fc2(x)\n",
    "#             return x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "c5bd5968-5922-4035-bfa2-75a3572b11c3",
   "metadata": {},
   "outputs": [],
   "source": [
    "class NetS(nn.Module):\n",
    "        def __init__(self):\n",
    "            super(NetS, self).__init__()\n",
    "            self.conv1 = nn.Conv2d(1, 32, 3, 1)\n",
    "            self.conv2 = nn.Conv2d(32, 64, 3, 1)\n",
    "            self.fc1 = nn.Linear(12544, 128)\n",
    "            self.fc2 = nn.Linear(128, 10)\n",
    "            self.bn1 = nn.BatchNorm2d(32)\n",
    "            self.bn2 = nn.BatchNorm2d(64)\n",
    "    \n",
    "        def forward(self, x):\n",
    "            x = F.relu(self.conv1(x))\n",
    "            x = self.bn1(x)\n",
    "            x = F.relu(self.conv2(x))\n",
    "            x = self.bn2(x)\n",
    "            x = F.max_pool2d(x, 2)\n",
    "            x = torch.flatten(x, 1)\n",
    "            x = F.relu(self.fc1(x))\n",
    "            x = self.fc2(x)\n",
    "            return x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "5badb174-6c13-4dcb-b728-bffee591fec3",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_victim_clone(args):\n",
    "    \n",
    "    student = NetS().to(args.device)\n",
    "    victim = torch.load(args.victim_path, map_location=args.device)\n",
    "    return victim , student"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b0f7b72a-4a58-4a63-9dd1-db77d69bafec",
   "metadata": {},
   "source": [
    "### Utilites"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "a72d70bf-5c0f-4601-a990-44ceaa0ae003",
   "metadata": {},
   "outputs": [],
   "source": [
    "class Args:\n",
    "    def __init__(self, device, seed, epochs, batch_size,num_timesteps, img_n, img_c, momentum,\n",
    "                 img_w, img_h, lr_G, lr_C, lr_hee, lr_z, weight_decay, N_G, N_C, \n",
    "                 steps_hee, grad_accumulation_steps, std_aug, lam, label_smooth_factor,\n",
    "                 victim_path, N_classes, debug, save_dir):\n",
    "        \n",
    "        self.device = device\n",
    "        self.seed = seed\n",
    "        self.epochs = epochs\n",
    "        self.batch_size = batch_size\n",
    "        self.num_timesteps = num_timesteps\n",
    "        self.img_n = img_n\n",
    "        self.img_c = img_c\n",
    "        self.img_w = img_w\n",
    "        self.img_h = img_h\n",
    "        self.lr_G = lr_G\n",
    "        self.lr_C = lr_C\n",
    "        self.lr_hee = lr_hee\n",
    "        self.lr_z = lr_z\n",
    "        self.weight_decay = weight_decay\n",
    "        self.momentum = momentum\n",
    "        self.N_G = N_G\n",
    "        self.N_C = N_C\n",
    "        self.steps_hee = steps_hee\n",
    "        self.grad_accumulation_steps = grad_accumulation_steps\n",
    "        self.std_aug = std_aug\n",
    "        self.lam = lam\n",
    "        self.victim_path = victim_path\n",
    "        self.N_classes = N_classes\n",
    "        self.debug = debug\n",
    "        self.victim_path = victim_path\n",
    "        self.label_smooth_factor = label_smooth_factor\n",
    "        self.save_dir = save_dir"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "3acc036a-a271-4620-a5ba-22c104ac0b49",
   "metadata": {},
   "outputs": [],
   "source": [
    "class FakeDataset(torch.utils.data.Dataset):\n",
    "    \"\"\"Some Information about FakeDataset\"\"\"\n",
    "\n",
    "    def __init__(self, root=\"\", transform=None):\n",
    "        super(FakeDataset, self).__init__()\n",
    "\n",
    "        self.transform = transform\n",
    "\n",
    "        history_images = np.load(os.path.join(root, \"fake_images.npy\"))\n",
    "        self.images = torch.from_numpy(history_images)\n",
    "\n",
    "    def __getitem__(self, index):\n",
    "        image = self.images[index]\n",
    "\n",
    "        return image\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.images)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "5dbcf080-786f-4378-8e0f-719bc6240b7f",
   "metadata": {},
   "outputs": [],
   "source": [
    "class TensorDataset(Dataset):\n",
    "    def __init__(self, tensor):\n",
    "        self.tensor = tensor\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.tensor)\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        return self.tensor[idx]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "90760983-d005-439a-b334-28565629571a",
   "metadata": {},
   "outputs": [],
   "source": [
    "class DataIter(object):\n",
    "    def __init__(self, dataloader):\n",
    "        self.dataloader = dataloader\n",
    "        self._iter = iter(self.dataloader)\n",
    "\n",
    "    def next(self):\n",
    "        try:\n",
    "            data = next(self._iter)\n",
    "        except StopIteration:\n",
    "            self._iter = iter(self.dataloader)\n",
    "            data = next(self._iter)\n",
    "        return data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "283f433e-1666-439c-9120-40ab921109ad",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_standard_augment(img_w, img_h):\n",
    "    std_aug = augmentation.container.ImageSequential(\n",
    "    augmentation.RandomCrop(size=[img_w, img_h], padding=4),\n",
    "    augmentation.RandomHorizontalFlip(),\n",
    ")\n",
    "    return std_aug"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "5bc23b46-cae7-4f8a-a471-986e7a97d28e",
   "metadata": {},
   "outputs": [],
   "source": [
    "def strong_aug(image):\n",
    "    device = image.device\n",
    "    image = TF.center_crop(\n",
    "        image,\n",
    "        [int(32.0 * random.uniform(0.95, 1.0)), int(32.0 * random.uniform(0.95, 1.0))],\n",
    "    )\n",
    "    image = TF.resize(image, [32, 32])\n",
    "    noise = torch.randn_like(image).to(device) * 0.001\n",
    "    image = torch.clamp(image + noise, 0.0, 1.0)\n",
    "    if random.uniform(0, 1) > 0.5:\n",
    "        image = TF.vflip(image)\n",
    "    if random.uniform(0, 1) > 0.5:\n",
    "        image = TF.hflip(image)\n",
    "    angles = [-15, 0, 15]\n",
    "    angle = random.choice(angles)\n",
    "    image = TF.rotate(image, angle)\n",
    "    return image"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "41ea93c1-1fec-4a94-bba0-fe084544b740",
   "metadata": {},
   "outputs": [],
   "source": [
    "def smooth_one_hot(args, true_labels):\n",
    "    \"\"\"\n",
    "    if smoothing == 0, it's one-hot method\n",
    "    if 0 < smoothing < 1, it's smooth method\n",
    "    \"\"\"\n",
    "    device = true_labels.device\n",
    "    true_labels = torch.nn.functional.one_hot(true_labels, args.N_classes).detach().cpu()\n",
    "    assert 0 <= args.label_smooth_factor < 1\n",
    "    confidence = 1.0 - args.label_smooth_factor\n",
    "    label_shape = torch.Size((true_labels.size(0), args.N_classes))\n",
    "    with torch.no_grad():\n",
    "        true_dist = torch.empty(size=label_shape, device=true_labels.device)\n",
    "        true_dist.fill_(args.label_smooth_factor / (args.N_classes - 1))\n",
    "        _, index = torch.max(true_labels, 1)\n",
    "\n",
    "        true_dist.scatter_(1, torch.LongTensor(index.unsqueeze(1)), confidence)\n",
    "    return true_dist.to(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "c27ac394-f91a-4698-8a3a-ad5f3c5c0819",
   "metadata": {},
   "outputs": [],
   "source": [
    "def evaluate(net, testloader):\n",
    "    correct = 0\n",
    "    total = 0\n",
    "    with torch.no_grad():\n",
    "        for data in testloader:\n",
    "            images, labels = data\n",
    "            outputs = net(images.to(device))\n",
    "            _, predicted = torch.max(outputs.data, 1)\n",
    "            total += labels.size(0)\n",
    "            correct += (predicted == labels.to(device)).sum().item()\n",
    "    \n",
    "    print(f'Accuracy of the network on the 10,000 test images: {100 * correct / total:.2f}%')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "eb7ce857-db53-4dfb-88ae-ea5e4324d282",
   "metadata": {},
   "outputs": [],
   "source": [
    "def save_batch_fake(args, images, epoch):\n",
    "    images = images.detach().cpu().numpy()\n",
    "    images_filename = os.path.join(args.save_dir, \"fake_images.npy\")\n",
    "\n",
    "    if epoch > 1:\n",
    "        org_images = np.load(images_filename)\n",
    "\n",
    "        images = np.concatenate((org_images, images), 0)\n",
    "\n",
    "    np.save(images_filename, images)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "75df346e-60d5-4525-bcd9-90e7065934d4",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Function to calculate the Gram matrix\n",
    "def gram_matrix(x):\n",
    "    return torch.matmul(x, x.t())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "64d75aaf-ae69-479d-9483-32cacc82991c",
   "metadata": {},
   "source": [
    "### DFME++ Attack"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "fb06396f-c99b-47c5-b427-16cd013b2370",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Loss function: L1 loss between student and teacher Gram matrices\n",
    "def l1_loss_between_grams(student_probs, teacher_probs):  # Student prob : time steps, classes. \n",
    "    student_gram = gram_matrix(student_probs)\n",
    "    teacher_gram = gram_matrix(teacher_probs)\n",
    "    return F.l1_loss(student_gram, teacher_gram)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "c2614f5c-9a4b-4441-b4f8-028b44634bed",
   "metadata": {},
   "outputs": [],
   "source": [
    "class Entropy_Loss(nn.Module):\n",
    "    def __init__(self, reduction=\"mean\"):\n",
    "        super(Entropy_Loss, self).__init__()\n",
    "        self.reduction = reduction\n",
    "\n",
    "    def forward(self, x):  # x should be logits\n",
    "        b = F.softmax(x, dim=1) * F.log_softmax(x, dim=1)\n",
    "        b = 1.0 * b.sum(dim=1)\n",
    "        if self.reduction == \"mean\":\n",
    "            return b.mean()\n",
    "        elif self.reduction == \"sum\":\n",
    "            return b.sum()\n",
    "        elif self.reduction == \"none\":\n",
    "            return b"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "f5abf25b-307f-4a83-bc46-fc8ce8b3136b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# def cross_entropy(outputs, smooth_labels):\n",
    "#     loss = torch.nn.KLDivLoss(reduction=\"batchmean\")\n",
    "#     return loss(F.log_softmax(outputs, dim=1), smooth_labels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "34ae25b1-adc2-4c90-b107-e5fe5d2dea5c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# def generate_hee(args, model, x):\n",
    "#     model.eval()\n",
    "#     x_hee = x.detach() + 0.001 * torch.torch.randn(x.shape).to(args.device).detach()\n",
    "#     for _ in range(args.steps_hee):\n",
    "#         x_hee.requires_grad_()\n",
    "#         with torch.enable_grad():\n",
    "#             pred = model(x_hee)\n",
    "#             loss = Entropy_Loss(reduction=\"mean\")(pred)\n",
    "#         grad = torch.autograd.grad(loss, [x_hee])[0] \n",
    "#         x_hee = x_hee.detach() + args.lr_hee * torch.sign(grad.detach())\n",
    "#         x_hee = torch.clamp(x_hee, 0.0, 1.0)\n",
    "#     model.train()\n",
    "\n",
    "#     return x_hee"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "id": "24d8f970-f4a2-41c0-a3d5-0394941a31a0",
   "metadata": {},
   "outputs": [],
   "source": [
    "def train_generator(args, generator_model, clone_model, epoch):\n",
    "\n",
    "    generator_model.train()\n",
    "    clone_model.eval()\n",
    "    \n",
    "    best_fake = None\n",
    "    best_loss = 1e6\n",
    "    \n",
    "    if args.debug: print('Debug(train_generator) :-> Generating Images using Generator Model')\n",
    "    z = torch.randn(size=(args.img_n, args.img_c,args.img_w, args.img_h )).to(args.device)\n",
    "    z.requires_grad = True\n",
    "    \n",
    "    optimizer_G = torch.optim.Adam([{\"params\": generator_model.parameters()}, {\"params\": [z], \"lr\": args.lr_z}], lr=args.lr_G, betas=[0.5, 0.999])\n",
    "    # pseudo_y = torch.randint(low=0, high=args.N_classes, size=(args.img_n,)).to(args.device)\n",
    "    # soft_labels = smooth_one_hot(args, pseudo_y)\n",
    "    criterion = Entropy_Loss()\n",
    "    \n",
    "    if args.debug: print('Debug(train_generator) :-> Starting Generator Training')\n",
    "    for step in range(args.N_G):\n",
    "    \n",
    "        fake = torch.stack(generator_model(z)).squeeze(1)\n",
    "        aug_fake = args.std_aug(fake)  # data augmentation to fake images. \n",
    "        \n",
    "        logits = clone_model(aug_fake)\n",
    "        # print(logits.shape)\n",
    "        loss = criterion(logits)\n",
    "    \n",
    "    \n",
    "        with torch.no_grad():\n",
    "            if best_loss > loss.item() or best_fake is None:\n",
    "                best_loss = loss.item()\n",
    "                best_fake = fake\n",
    "        \n",
    "        optimizer_G.zero_grad()\n",
    "        loss.backward()\n",
    "        # torch.nn.utils.clip_grad_norm(clone_model.parameters(), max_norm = 1)\n",
    "        optimizer_G.step()\n",
    "    print(f\"Generator Step {step} average loss: {loss}\")\n",
    "    save_batch_fake(args, best_fake.data, epoch)\n",
    "    if args.debug: print('Debug(train_generator) :-> Generator Training Ended')\n",
    "    return generator_model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "id": "39ca31e0-8315-459e-bc2b-f013c5091674",
   "metadata": {},
   "outputs": [],
   "source": [
    "def train_clone(args, generator_model, clone_model, victim_model, optimizer_C):\n",
    "\n",
    "    generator_model.eval()\n",
    "    clone_model.train()\n",
    "    victim_model.eval()\n",
    "    \n",
    "    dataset = FakeDataset(root=args.save_dir)\n",
    "    data_loader = torch.utils.data.DataLoader(\n",
    "        dataset,\n",
    "        batch_size=args.batch_size,\n",
    "        shuffle=True,\n",
    "    )\n",
    "    data_iter = DataIter(data_loader)\n",
    "    \n",
    "    victim_classes_fired = np.zeros(args.N_classes)\n",
    "    clone_classes_fired = np.zeros(args.N_classes)\n",
    "    losses = []\n",
    "    if args.debug: print('Debug(train_clone) :-> Starting Clone Model Training')        \n",
    "    for step in range(args.N_C):\n",
    "        fake = data_iter.next().to(args.device)\n",
    "        aug_fake = args.std_aug(fake)  # already applied before saving\n",
    "        # fake_hee = generate_hee(args, clone_model,strong_aug(aug_fake))\n",
    "        \n",
    "        logits_T = victim_model(aug_fake).detach() \n",
    "        # print(logits.T)\n",
    "        hard_labels = logits_T.topk(1, 1)[1].reshape(-1)\n",
    "        victim_probs = F.softmax(logits_T)\n",
    "        np.add.at(victim_classes_fired, hard_labels.cpu().numpy() , 1)\n",
    "        \n",
    "        logits_C = clone_model(aug_fake)\n",
    "        clone_probs = F.softmax(logits_C)\n",
    "        np.add.at(clone_classes_fired, logits_C.topk(1, 1)[1].reshape(-1).cpu().numpy() , 1)\n",
    "        \n",
    "        loss = l1_loss_between_grams(clone_probs, victim_probs)\n",
    "        losses.append(loss.item())\n",
    "        optimizer_C.zero_grad()\n",
    "        loss.backward()\n",
    "        optimizer_C.step()\n",
    "        if step % 200 == 0:\n",
    "            print(f\"Clone Steps {step} average loss: {sum(losses[-len(data_loader):])/len(data_loader)}\")\n",
    "            print(f\"Clone Steps {step} Victim Classes Fired: {victim_classes_fired})\")\n",
    "            print(f\"Clone Steps {step} Clone Classes Fired: {clone_classes_fired})\")\n",
    "    if args.debug: print('Debug(train_clone) :-> Clone Model Training Ended') \n",
    "    return (generator_model, clone_model, victim_model, optimizer_C)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "id": "9fb4a0d0-24b1-4475-b383-2091324cdc64",
   "metadata": {},
   "outputs": [],
   "source": [
    "debug = 1 #To debug code\n",
    "device = torch.device('cuda') #device placement cpu or gpu\n",
    "seed = 10 #seed for consistent result\n",
    "epochs = 10 #number of epochs to train\n",
    "batch_size = 256 #batchsize\n",
    "num_timesteps = 100 #timestamps in multistepgenerator\n",
    "img_n = 1 \n",
    "img_c = 1 #image channel\n",
    "img_w = 32 #image size\n",
    "img_h = 32 #image size\n",
    "lr_z = 0.01 #learning rate of latent code\n",
    "lr_G = 0.001 #learning rate of Generator\n",
    "lr_C = 0.001 #learing rate of clone model\n",
    "lr_hee = 0.03 #perturb number of steps\n",
    "weight_decay = 1e-4 #Optimizer parameter: decay's weight update\n",
    "momentum = 0.9 #Optimizer parameter: Remeber past information 1/momentum times\n",
    "N_G = 100 #Diffuser train steps\n",
    "N_C = 500 #Clone model steps \n",
    "steps_hee = 10 #number of epochs to train\n",
    "grad_accumulation_steps = 16 #update model after no.of steps\n",
    "std_aug = get_standard_augment(img_w, img_h) #standard augmentation: flip, crop\n",
    "lam = 0.009 #hyperparameter for balancing two loss terms in diffuser\n",
    "victim_path = \"Model/fashion_mnist.pt\" #clone model path\n",
    "N_classes = 10 #No.of classes to predict\n",
    "label_smooth_factor = 0.2 #Hard to soft logits\n",
    "save_dir = r'Gen_Imgs/Gram' #Folder to save genrator images"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "id": "bf41408d-6de7-4bbe-b9fb-8c3e2e641a0c",
   "metadata": {},
   "outputs": [],
   "source": [
    "args = Args(\n",
    "        debug = debug,\n",
    "        device = device,\n",
    "        seed = seed,\n",
    "        epochs = epochs,\n",
    "        batch_size = batch_size,\n",
    "        num_timesteps = num_timesteps,\n",
    "        img_n = img_n,\n",
    "        img_c = img_c,\n",
    "        img_w = img_w,\n",
    "        img_h = img_h,\n",
    "        lr_G = lr_G,\n",
    "        lr_C = lr_C,\n",
    "        lr_z = lr_z,\n",
    "        lr_hee = lr_hee,\n",
    "        weight_decay = weight_decay,\n",
    "        momentum = momentum,\n",
    "        N_G = N_G,\n",
    "        N_C = N_C,\n",
    "        steps_hee = steps_hee,\n",
    "        grad_accumulation_steps = grad_accumulation_steps,\n",
    "        std_aug = std_aug,\n",
    "        lam = lam,\n",
    "        victim_path = victim_path,\n",
    "        N_classes = N_classes,\n",
    "        label_smooth_factor = label_smooth_factor,\n",
    "        save_dir = save_dir\n",
    "    )\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "1d587785-14be-4afe-a16a-f6b15b88d3f1",
   "metadata": {},
   "outputs": [],
   "source": [
    "torch.manual_seed(args.seed)\n",
    "torch.cuda.manual_seed(args.seed)\n",
    "torch.backends.cudnn.deterministic = True\n",
    "torch.backends.cudnn.benchmark = False"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "id": "84d79aed-b9c5-4f0a-ab98-646d8c2a7fe6",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "generator_model =  get_generator(args)\n",
    "victim_model, clone_model = get_victim_clone(args)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "18130477-043a-4282-ace6-554523132498",
   "metadata": {},
   "outputs": [],
   "source": [
    "optimizer_C = torch.optim.AdamW(\n",
    "        clone_model.parameters(),\n",
    "        lr=args.lr_C,\n",
    "        weight_decay=args.weight_decay,\n",
    "    )\n",
    "scheduler_lr = torch.optim.lr_scheduler.CosineAnnealingLR(\n",
    "    optimizer_C, args.epochs, eta_min=2e-4\n",
    ")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "2ac01e74-082d-4bb8-96aa-653e01dee40a",
   "metadata": {},
   "outputs": [],
   "source": [
    "transform = transforms.Compose([transforms.ToTensor(), transforms.Resize((32, 32))])\n",
    "testset = torchvision.datasets.FashionMNIST(root='./data', train=False, download=True, transform=transform)\n",
    "testloader = DataLoader(testset, batch_size=32, shuffle=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "8a070d09-a52b-4139-9784-583a861ffc35",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Dataset FashionMNIST\n",
       "    Number of datapoints: 10000\n",
       "    Root location: ./data\n",
       "    Split: Test\n",
       "    StandardTransform\n",
       "Transform: Compose(\n",
       "               ToTensor()\n",
       "               Resize(size=(32, 32), interpolation=bilinear, max_size=None, antialias=True)\n",
       "           )"
      ]
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "testset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "id": "5f35c1fa-02e1-49c6-90cf-3527b91e0510",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy of the network on the 10,000 test images: 92.07%\n",
      "Accuracy of the network on the 10,000 test images: 13.11%\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "(None, None)"
      ]
     },
     "execution_count": 64,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "evaluate(victim_model, testloader), evaluate(clone_model, testloader)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "id": "5cd7e96c-9df4-4f02-a4db-21fcfca02c6b",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|                                                                                                                                                                                    | 0/10 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Debug(train_generator) :-> Generating Images using Generator Model\n",
      "Debug(train_generator) :-> Starting Generator Training\n",
      "Generator Step 99 average loss: -0.3733247220516205\n",
      "Debug(train_generator) :-> Generator Training Ended\n",
      "--------------------------------------------------\n",
      "Debug(train_clone) :-> Starting Clone Model Training\n",
      "Clone Steps 0 average loss: 0.8021481037139893\n",
      "Clone Steps 0 Victim Classes Fired: [ 0.  4.  0.  0.  0. 94.  1.  0.  1.  0.])\n",
      "Clone Steps 0 Clone Classes Fired: [ 1. 13.  3.  1. 21. 22. 37.  0.  0.  2.])\n",
      "Clone Steps 200 average loss: 0.7305222749710083\n",
      "Clone Steps 200 Victim Classes Fired: [9.0000e+00 8.2200e+02 1.9000e+01 0.0000e+00 0.0000e+00 1.8591e+04\n",
      " 3.8000e+01 6.0000e+00 5.4400e+02 7.1000e+01])\n",
      "Clone Steps 200 Clone Classes Fired: [3.450e+02 4.068e+03 4.270e+02 1.640e+02 3.366e+03 3.856e+03 6.948e+03\n",
      " 2.860e+02 5.000e+00 6.350e+02])\n",
      "Clone Steps 400 average loss: 0.7488370537757874\n",
      "Clone Steps 400 Victim Classes Fired: [1.5000e+01 1.6810e+03 3.5000e+01 0.0000e+00 1.0000e+00 3.6998e+04\n",
      " 7.9000e+01 1.1000e+01 1.1390e+03 1.4100e+02])\n",
      "Clone Steps 400 Clone Classes Fired: [6.8800e+02 8.0870e+03 8.5100e+02 3.2700e+02 6.7340e+03 7.8530e+03\n",
      " 1.3743e+04 5.5800e+02 1.0000e+01 1.2490e+03])\n",
      "Debug(train_clone) :-> Clone Model Training Ended\n",
      "--------------------------------------------------\n",
      "[0.0004398230701537494]\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 10%|█████████████████▏                                                                                                                                                          | 1/10 [01:08<10:15, 68.42s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy of the network on the 10,000 test images: 13.11%\n",
      "\n",
      "Debug(train_generator) :-> Generating Images using Generator Model\n",
      "Debug(train_generator) :-> Starting Generator Training\n",
      "Generator Step 99 average loss: -0.3028698265552521\n",
      "Debug(train_generator) :-> Generator Training Ended\n",
      "--------------------------------------------------\n",
      "Debug(train_clone) :-> Starting Clone Model Training\n",
      "Clone Steps 0 average loss: 0.7174571752548218\n",
      "Clone Steps 0 Victim Classes Fired: [  0.   8.   0.   0.   0. 176.   0.   0.  14.   2.])\n",
      "Clone Steps 0 Clone Classes Fired: [ 4. 42.  4.  1. 39. 44. 59.  3.  0.  4.])\n",
      "Clone Steps 200 average loss: 0.8196738958358765\n",
      "Clone Steps 200 Victim Classes Fired: [5.700e+01 1.380e+03 4.700e+01 1.250e+02 5.000e+00 3.677e+04 7.800e+01\n",
      " 1.100e+01 1.521e+03 2.060e+02])\n",
      "Clone Steps 200 Clone Classes Fired: [4.3800e+02 8.5320e+03 7.1600e+02 2.1900e+02 7.5510e+03 7.9300e+03\n",
      " 1.2931e+04 7.4000e+02 6.0000e+00 1.1370e+03])\n",
      "Clone Steps 400 average loss: 0.6983717679977417\n",
      "Clone Steps 400 Victim Classes Fired: [1.0300e+02 2.7230e+03 7.5000e+01 2.3600e+02 5.0000e+00 7.3376e+04\n",
      " 1.6800e+02 2.4000e+01 3.0800e+03 4.1000e+02])\n",
      "Clone Steps 400 Clone Classes Fired: [8.2800e+02 1.7018e+04 1.4390e+03 4.3500e+02 1.4986e+04 1.5757e+04\n",
      " 2.5916e+04 1.5340e+03 1.3000e+01 2.2740e+03])\n",
      "Debug(train_clone) :-> Clone Model Training Ended\n",
      "--------------------------------------------------\n",
      "[0.0002]\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 20%|██████████████████████████████████▍                                                                                                                                         | 2/10 [02:23<09:36, 72.11s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy of the network on the 10,000 test images: 13.11%\n",
      "\n",
      "Debug(train_generator) :-> Generating Images using Generator Model\n",
      "Debug(train_generator) :-> Starting Generator Training\n",
      "Generator Step 99 average loss: -0.4623737335205078\n",
      "Debug(train_generator) :-> Generator Training Ended\n",
      "--------------------------------------------------\n",
      "Debug(train_clone) :-> Starting Clone Model Training\n",
      "Clone Steps 0 average loss: 0.32029563188552856\n",
      "Clone Steps 0 Victim Classes Fired: [  1.   8.   0.   1.   0. 210.   2.   0.  33.   1.])\n",
      "Clone Steps 0 Clone Classes Fired: [ 3. 56.  5.  5. 45. 40. 79. 15.  1.  7.])\n",
      "Clone Steps 200 average loss: 0.6351637244224548\n",
      "Clone Steps 200 Victim Classes Fired: [8.2000e+01 7.5900e+02 2.1000e+01 2.5100e+02 0.0000e+00 2.4661e+04\n",
      " 3.6400e+02 2.6000e+01 3.8390e+03 2.5300e+02])\n",
      "Clone Steps 200 Clone Classes Fired: [ 324. 5565.  616.  365. 5538. 5842. 9242. 1821.   92.  851.])\n",
      "Clone Steps 400 average loss: 0.6018776595592499\n",
      "Clone Steps 400 Victim Classes Fired: [1.7400e+02 1.4450e+03 5.2000e+01 4.8200e+02 2.0000e+00 4.9099e+04\n",
      " 7.4200e+02 5.1000e+01 7.7410e+03 4.6800e+02])\n",
      "Clone Steps 400 Clone Classes Fired: [  638. 11052.  1242.   796. 10927. 11658. 18446.  3583.   192.  1722.])\n",
      "Debug(train_clone) :-> Clone Model Training Ended\n",
      "--------------------------------------------------\n",
      "[0.0004398230701537477]\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 30%|███████████████████████████████████████████████████▌                                                                                                                        | 3/10 [03:31<08:14, 70.58s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy of the network on the 10,000 test images: 13.11%\n",
      "\n",
      "Debug(train_generator) :-> Generating Images using Generator Model\n",
      "Debug(train_generator) :-> Starting Generator Training\n",
      "Generator Step 99 average loss: -0.25410133600234985\n",
      "Debug(train_generator) :-> Generator Training Ended\n",
      "--------------------------------------------------\n",
      "Debug(train_clone) :-> Starting Clone Model Training\n",
      "Clone Steps 0 average loss: 0.3350113034248352\n",
      "Clone Steps 0 Victim Classes Fired: [  1.   5.   0.   0.   0. 216.   3.   0.  30.   1.])\n",
      "Clone Steps 0 Clone Classes Fired: [ 2. 42.  7.  4. 29. 52. 95. 11.  2. 12.])\n",
      "Clone Steps 200 average loss: 0.6032398045063019\n",
      "Clone Steps 200 Victim Classes Fired: [  141.   799.    40.   264.     0. 33159.   395.    56.  5101.   301.])\n",
      "Clone Steps 200 Clone Classes Fired: [  663.  6835.  1119.   519.  6914.  7459. 13142.  1977.   113.  1515.])\n",
      "Clone Steps 400 average loss: 0.6632165014743805\n",
      "Clone Steps 400 Victim Classes Fired: [  275.  1615.    74.   518.     0. 66144.   788.   109. 10170.   563.])\n",
      "Clone Steps 400 Clone Classes Fired: [ 1317. 13509.  2223.  1016. 13770. 14985. 26194.  3962.   216.  3064.])\n",
      "Debug(train_clone) :-> Clone Model Training Ended\n",
      "--------------------------------------------------\n",
      "[0.0011358167275627585]\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 40%|████████████████████████████████████████████████████████████████████▊                                                                                                       | 4/10 [04:45<07:10, 71.78s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy of the network on the 10,000 test images: 13.11%\n",
      "\n",
      "Debug(train_generator) :-> Generating Images using Generator Model\n",
      "Debug(train_generator) :-> Starting Generator Training\n",
      "Generator Step 99 average loss: -0.31780606508255005\n",
      "Debug(train_generator) :-> Generator Training Ended\n",
      "--------------------------------------------------\n",
      "Debug(train_clone) :-> Starting Clone Model Training\n",
      "Clone Steps 0 average loss: 0.3286469876766205\n",
      "Clone Steps 0 Victim Classes Fired: [  1.   5.   0.   1.   0. 214.   6.   0.  28.   1.])\n",
      "Clone Steps 0 Clone Classes Fired: [ 3. 42.  8.  4. 59. 40. 68. 18.  1. 13.])\n",
      "Clone Steps 200 average loss: 0.6070368885993958\n",
      "Clone Steps 200 Victim Classes Fired: [1.8000e+02 8.2800e+02 4.0000e+01 3.8800e+02 1.0000e+00 4.0653e+04\n",
      " 6.5300e+02 7.1000e+01 7.0140e+03 4.2800e+02])\n",
      "Clone Steps 200 Clone Classes Fired: [  735.  8423.  1263.   723.  8887.  9549. 15982.  2793.   152.  1749.])\n",
      "Clone Steps 400 average loss: 0.5909522771835327\n",
      "Clone Steps 400 Victim Classes Fired: [3.7700e+02 1.6470e+03 8.2000e+01 7.5000e+02 1.0000e+00 8.1028e+04\n",
      " 1.2580e+03 1.2600e+02 1.4103e+04 8.8400e+02])\n",
      "Clone Steps 400 Clone Classes Fired: [ 1466. 17037.  2572.  1453. 17756. 18797. 31848.  5488.   325.  3514.])\n",
      "Debug(train_clone) :-> Clone Model Training Ended\n",
      "--------------------------------------------------\n",
      "[0.0022198522637668847]\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 50%|██████████████████████████████████████████████████████████████████████████████████████                                                                                      | 5/10 [06:03<06:09, 73.98s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy of the network on the 10,000 test images: 13.11%\n",
      "\n",
      "Debug(train_generator) :-> Generating Images using Generator Model\n",
      "Debug(train_generator) :-> Starting Generator Training\n",
      "Generator Step 99 average loss: -0.24762704968452454\n",
      "Debug(train_generator) :-> Generator Training Ended\n",
      "--------------------------------------------------\n",
      "Debug(train_clone) :-> Starting Clone Model Training\n",
      "Clone Steps 0 average loss: 0.2037245233853658\n",
      "Clone Steps 0 Victim Classes Fired: [  0.   5.   1.   4.   0. 202.   4.   0.  40.   0.])\n",
      "Clone Steps 0 Clone Classes Fired: [ 2. 49.  8.  4. 32. 48. 90. 14.  1.  8.])\n",
      "Clone Steps 200 average loss: 0.6093002756436666\n",
      "Clone Steps 200 Victim Classes Fired: [1.7300e+02 6.3300e+02 2.0000e+01 2.4000e+02 0.0000e+00 3.2703e+04\n",
      " 4.4300e+02 7.3000e+01 5.6510e+03 2.6400e+02])\n",
      "Clone Steps 200 Clone Classes Fired: [  856.  6410.  1321.   535.  6398.  7402. 13614.  1965.   100.  1599.])\n",
      "Clone Steps 400 average loss: 0.6316084663073221\n",
      "Clone Steps 400 Victim Classes Fired: [3.4300e+02 1.2710e+03 4.3000e+01 4.8200e+02 0.0000e+00 6.5380e+04\n",
      " 8.4500e+02 1.2100e+02 1.1299e+04 5.2800e+02])\n",
      "Clone Steps 400 Clone Classes Fired: [ 1675. 12790.  2745.  1042. 12995. 14888. 26854.  3875.   213.  3235.])\n",
      "Debug(train_clone) :-> Clone Model Training Ended\n",
      "--------------------------------------------------\n",
      "[0.003585816727562763]\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 60%|███████████████████████████████████████████████████████████████████████████████████████████████████████▏                                                                    | 6/10 [07:15<04:53, 73.48s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy of the network on the 10,000 test images: 13.11%\n",
      "\n",
      "Debug(train_generator) :-> Generating Images using Generator Model\n",
      "Debug(train_generator) :-> Starting Generator Training\n",
      "Generator Step 99 average loss: -0.23114654421806335\n",
      "Debug(train_generator) :-> Generator Training Ended\n",
      "--------------------------------------------------\n",
      "Debug(train_clone) :-> Starting Clone Model Training\n",
      "Clone Steps 0 average loss: 0.20089348157246908\n",
      "Clone Steps 0 Victim Classes Fired: [  4.   1.   1.   2.   0. 200.   4.   0.  42.   2.])\n",
      "Clone Steps 0 Clone Classes Fired: [ 3. 35. 10.  4. 37. 49. 95. 17.  0.  6.])\n",
      "Clone Steps 200 average loss: 0.6493988633155823\n",
      "Clone Steps 200 Victim Classes Fired: [2.4400e+02 7.3000e+02 3.5000e+01 2.8100e+02 0.0000e+00 3.8396e+04\n",
      " 4.5700e+02 5.3000e+01 6.3260e+03 3.7800e+02])\n",
      "Clone Steps 200 Clone Classes Fired: [ 1076.  7534.  1611.   570.  7693.  8369. 15775.  2238.   113.  1921.])\n",
      "Clone Steps 400 average loss: 0.637961208820343\n",
      "Clone Steps 400 Victim Classes Fired: [4.6400e+02 1.4580e+03 7.6000e+01 5.2500e+02 1.0000e+00 7.6557e+04\n",
      " 8.6200e+02 1.1000e+02 1.2822e+04 7.3700e+02])\n",
      "Clone Steps 400 Clone Classes Fired: [ 2120. 15138.  3258.  1170. 15113. 16823. 31424.  4499.   235.  3832.])\n",
      "Debug(train_clone) :-> Clone Model Training Ended\n",
      "--------------------------------------------------\n",
      "[0.005100000000000008]\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 70%|████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████▍                                                   | 7/10 [08:29<03:40, 73.60s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy of the network on the 10,000 test images: 13.11%\n",
      "\n",
      "Debug(train_generator) :-> Generating Images using Generator Model\n",
      "Debug(train_generator) :-> Starting Generator Training\n",
      "Generator Step 99 average loss: -0.2764979600906372\n",
      "Debug(train_generator) :-> Generator Training Ended\n",
      "--------------------------------------------------\n",
      "Debug(train_clone) :-> Starting Clone Model Training\n",
      "Clone Steps 0 average loss: 0.1678173989057541\n",
      "Clone Steps 0 Victim Classes Fired: [  1.   5.   0.   1.   0. 217.   2.   0.  30.   0.])\n",
      "Clone Steps 0 Clone Classes Fired: [ 8. 42.  9.  4. 45. 47. 83.  8.  2.  8.])\n",
      "Clone Steps 200 average loss: 0.6419875621795654\n",
      "Clone Steps 200 Victim Classes Fired: [  209.   549.    34.   219.     0. 33016.   341.    47.  5508.   333.])\n",
      "Clone Steps 200 Clone Classes Fired: [  827.  6604.  1308.   507.  6503.  7480. 13437.  1870.    98.  1622.])\n",
      "Clone Steps 400 average loss: 0.6457650810480118\n",
      "Clone Steps 400 Victim Classes Fired: [  389.  1146.    68.   420.     0. 65973.   695.   114. 10800.   651.])\n",
      "Clone Steps 400 Clone Classes Fired: [ 1651. 13037.  2598.  1033. 12863. 14670. 27086.  3770.   224.  3324.])\n",
      "Debug(train_clone) :-> Clone Model Training Ended\n",
      "--------------------------------------------------\n",
      "[0.006614183272437254]\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 80%|█████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████▌                                  | 8/10 [09:40<02:25, 72.82s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy of the network on the 10,000 test images: 13.11%\n",
      "\n",
      "Debug(train_generator) :-> Generating Images using Generator Model\n",
      "Debug(train_generator) :-> Starting Generator Training\n",
      "Generator Step 99 average loss: -0.2772515118122101\n",
      "Debug(train_generator) :-> Generator Training Ended\n",
      "--------------------------------------------------\n",
      "Debug(train_clone) :-> Starting Clone Model Training\n",
      "Clone Steps 0 average loss: 0.17009992897510529\n",
      "Clone Steps 0 Victim Classes Fired: [  0.   2.   0.   0.   0. 218.   3.   1.  32.   0.])\n",
      "Clone Steps 0 Clone Classes Fired: [ 3. 42.  6.  2. 43. 43. 95. 13.  1.  8.])\n",
      "Clone Steps 200 average loss: 0.6697021722793579\n",
      "Clone Steps 200 Victim Classes Fired: [2.4100e+02 6.4600e+02 4.1000e+01 2.2700e+02 1.0000e+00 3.7192e+04\n",
      " 3.8600e+02 5.9000e+01 6.1070e+03 3.5600e+02])\n",
      "Clone Steps 200 Clone Classes Fired: [ 1070.  7153.  1690.   586.  7058.  8183. 15655.  1940.   105.  1816.])\n",
      "Clone Steps 400 average loss: 0.63919498026371\n",
      "Clone Steps 400 Victim Classes Fired: [4.8900e+02 1.2660e+03 6.5000e+01 4.3000e+02 1.0000e+00 7.4051e+04\n",
      " 7.3400e+02 1.2000e+02 1.2373e+04 7.2700e+02])\n",
      "Clone Steps 400 Clone Classes Fired: [ 2094. 14410.  3319.  1173. 13984. 16235. 31351.  3862.   202.  3626.])\n",
      "Debug(train_clone) :-> Clone Model Training Ended\n",
      "--------------------------------------------------\n",
      "[0.007980147736233135]\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 90%|██████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████▊                 | 9/10 [10:53<01:12, 72.70s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy of the network on the 10,000 test images: 13.11%\n",
      "\n",
      "Debug(train_generator) :-> Generating Images using Generator Model\n",
      "Debug(train_generator) :-> Starting Generator Training\n",
      "Generator Step 99 average loss: -0.28388601541519165\n",
      "Debug(train_generator) :-> Generator Training Ended\n",
      "--------------------------------------------------\n",
      "Debug(train_clone) :-> Starting Clone Model Training\n",
      "Clone Steps 0 average loss: 0.16461628675460815\n",
      "Clone Steps 0 Victim Classes Fired: [  1.   4.   0.   0.   0. 215.   3.   3.  27.   3.])\n",
      "Clone Steps 0 Clone Classes Fired: [  9.  34.   7.   1.  40.  41. 103.  12.   0.   9.])\n",
      "Clone Steps 200 average loss: 0.6442815512418747\n",
      "Clone Steps 200 Victim Classes Fired: [  257.   750.    44.   226.     0. 41448.   399.    66.  6655.   411.])\n",
      "Clone Steps 200 Clone Classes Fired: [ 1211.  8019.  1912.   582.  7746.  8969. 17600.  2116.   103.  1998.])\n",
      "Clone Steps 400 average loss: 0.6427726745605469\n",
      "Clone Steps 400 Victim Classes Fired: [5.4000e+02 1.4860e+03 8.0000e+01 4.7400e+02 1.0000e+00 8.2732e+04\n",
      " 7.7500e+02 1.3600e+02 1.3234e+04 7.9800e+02])\n",
      "Clone Steps 400 Clone Classes Fired: [ 2447. 15828.  3815.  1186. 15620. 17734. 35234.  4182.   211.  3999.])\n",
      "Debug(train_clone) :-> Clone Model Training Ended\n",
      "--------------------------------------------------\n",
      "[0.009064183272437262]\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|███████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████| 10/10 [12:08<00:00, 72.82s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy of the network on the 10,000 test images: 13.11%\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    " for epoch in tqdm(range(1, args.epochs + 1)):\n",
    "     \n",
    "    generator_model = train_generator(args, generator_model, clone_model, epoch)\n",
    "    print('-'*50)\n",
    "    generator_model, clone_model, victim_model, optimizer_C = train_clone(args, generator_model, clone_model, victim_model, optimizer_C)\n",
    "    print('-'*50)\n",
    "    print(scheduler_lr.get_last_lr())\n",
    "    print()\n",
    "    evaluate(clone_model, testloader)\n",
    "    print()\n",
    "    scheduler_lr.step()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3c8bb994-3d88-48ad-bdba-5f0ff252be97",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python (DFME)",
   "language": "python",
   "name": "dfme"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.19"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}

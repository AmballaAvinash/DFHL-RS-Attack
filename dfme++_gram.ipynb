{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "209a4dd9-14d1-450b-8762-db36db43ef07",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-08-29T05:36:37.067108Z",
     "iopub.status.busy": "2024-08-29T05:36:37.067108Z",
     "iopub.status.idle": "2024-08-29T05:36:53.109272Z",
     "shell.execute_reply": "2024-08-29T05:36:53.107620Z",
     "shell.execute_reply.started": "2024-08-29T05:36:37.067108Z"
    }
   },
   "outputs": [],
   "source": [
    "import os\n",
    "import torch\n",
    "import random\n",
    "import warnings\n",
    "import numpy as np\n",
    "import torchvision\n",
    "import torch.nn as nn\n",
    "from tqdm import tqdm\n",
    "from copy import deepcopy\n",
    "from kornia import augmentation\n",
    "import torch.nn.functional as F\n",
    "import matplotlib.pyplot as plt\n",
    "from diffusers import UNet2DModel\n",
    "from datasets import load_dataset\n",
    "from torchvision import transforms\n",
    "from diffusers import DDPMScheduler\n",
    "from PIL import ImageDraw, ImageFont, Image\n",
    "from datasets import load_dataset, load_metric\n",
    "import torchvision.transforms.functional as TF\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "warnings.filterwarnings(\"ignore\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f1a83a42-7fa1-4069-a5ab-de1a26b60fbe",
   "metadata": {},
   "source": [
    "### Define Generator, Victim and Stolen"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "058833bf-736f-48ab-b1b4-20cbb202d88b",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-08-29T05:36:53.113489Z",
     "iopub.status.busy": "2024-08-29T05:36:53.113489Z",
     "iopub.status.idle": "2024-08-29T05:36:53.142615Z",
     "shell.execute_reply": "2024-08-29T05:36:53.142110Z",
     "shell.execute_reply.started": "2024-08-29T05:36:53.113489Z"
    }
   },
   "outputs": [],
   "source": [
    "class DoubleConv(nn.Module):\n",
    "    def __init__(self, in_channels, out_channels):\n",
    "        super().__init__()\n",
    "        self.conv = nn.Sequential(\n",
    "            nn.Conv2d(in_channels, out_channels, kernel_size=3, padding=1, bias=False),\n",
    "            nn.BatchNorm2d(out_channels),\n",
    "            nn.ReLU(inplace=True),\n",
    "            nn.Conv2d(out_channels, out_channels, kernel_size=3, padding=1, bias=False),\n",
    "            nn.BatchNorm2d(out_channels),\n",
    "            nn.ReLU(inplace=True)\n",
    "        )\n",
    "\n",
    "    def forward(self, x):\n",
    "        return self.conv(x)\n",
    "\n",
    "class UNet(nn.Module):\n",
    "    def __init__(self, in_channels, out_channels, features=[64, 128, 256, 512]):\n",
    "        super().__init__()\n",
    "        self.downs = nn.ModuleList()\n",
    "        self.ups = nn.ModuleList()\n",
    "        self.pool = nn.MaxPool2d(kernel_size=2, stride=2)\n",
    "\n",
    "        # Downsampling\n",
    "        for feature in features:\n",
    "            self.downs.append(DoubleConv(in_channels, feature))\n",
    "            in_channels = feature\n",
    "\n",
    "        # Upsampling\n",
    "        for feature in reversed(features):\n",
    "            self.ups.append(\n",
    "                nn.ConvTranspose2d(feature * 2, feature, kernel_size=2, stride=2)\n",
    "            )\n",
    "            self.ups.append(DoubleConv(feature * 2, feature))\n",
    "\n",
    "        self.bottleneck = DoubleConv(features[-1], features[-1] * 2)\n",
    "        self.final_conv = nn.Conv2d(features[0], out_channels, kernel_size=1)\n",
    "\n",
    "    def forward(self, x):\n",
    "        skip_connections = []\n",
    "\n",
    "        # Downsampling\n",
    "        for down in self.downs:\n",
    "            x = down(x)\n",
    "            skip_connections.append(x)\n",
    "            x = self.pool(x)\n",
    "\n",
    "        x = self.bottleneck(x)\n",
    "        skip_connections = skip_connections[::-1]\n",
    "\n",
    "        # Upsampling\n",
    "        for idx in range(0, len(self.ups), 2):\n",
    "            x = self.ups[idx](x)\n",
    "            skip_connection = skip_connections[idx // 2]\n",
    "\n",
    "            if x.shape != skip_connection.shape:\n",
    "                x = nn.functional.resize(x, size=skip_connection.shape[2:])\n",
    "\n",
    "            concat_skip = torch.cat((skip_connection, x), dim=1)\n",
    "            x = self.ups[idx + 1](concat_skip)\n",
    "\n",
    "        return self.final_conv(x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "0c002cc9-5599-440c-81a0-abe667f37c95",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-08-29T05:36:53.143628Z",
     "iopub.status.busy": "2024-08-29T05:36:53.143628Z",
     "iopub.status.idle": "2024-08-29T05:36:53.158163Z",
     "shell.execute_reply": "2024-08-29T05:36:53.158163Z",
     "shell.execute_reply.started": "2024-08-29T05:36:53.143628Z"
    }
   },
   "outputs": [],
   "source": [
    "def get_generator(args):\n",
    "    class MultiStepGenerator(nn.Module):\n",
    "        def __init__(self, args):\n",
    "            super(MultiStepGenerator, self).__init__()\n",
    "            self.unet =UNet(in_channels=args.img_c, out_channels=args.img_c)\n",
    "            self.num_timesteps = args.num_timesteps\n",
    "        \n",
    "        def forward(self, noise):\n",
    "            images = []\n",
    "            current_image = noise\n",
    "    \n",
    "            for _ in range(self.num_timesteps):\n",
    "                current_image = self.unet(current_image)\n",
    "                images.append(current_image)\n",
    "            \n",
    "            return images\n",
    "\n",
    "    return MultiStepGenerator(args).to(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "58c1448a-87e0-4758-b630-61a68a8e2a7f",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-08-29T05:36:53.160438Z",
     "iopub.status.busy": "2024-08-29T05:36:53.160438Z",
     "iopub.status.idle": "2024-08-29T05:36:53.176421Z",
     "shell.execute_reply": "2024-08-29T05:36:53.175423Z",
     "shell.execute_reply.started": "2024-08-29T05:36:53.160438Z"
    }
   },
   "outputs": [],
   "source": [
    "class Net(nn.Module):\n",
    "        def __init__(self):\n",
    "            super(Net, self).__init__()\n",
    "            self.conv1 = nn.Conv2d(1, 32, 3, 1)\n",
    "            self.conv2 = nn.Conv2d(32, 64, 3, 1)\n",
    "            self.fc1 = nn.Linear(12544, 128)\n",
    "            self.fc2 = nn.Linear(128, 10)\n",
    "    \n",
    "        def forward(self, x):\n",
    "            x = F.relu(self.conv1(x))\n",
    "            x = F.relu(self.conv2(x))\n",
    "            x = F.max_pool2d(x, 2)\n",
    "            x = torch.flatten(x, 1)\n",
    "            x = F.relu(self.fc1(x))\n",
    "            x = self.fc2(x)\n",
    "            return x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "c5bd5968-5922-4035-bfa2-75a3572b11c3",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-08-29T05:36:53.176729Z",
     "iopub.status.busy": "2024-08-29T05:36:53.176729Z",
     "iopub.status.idle": "2024-08-29T05:36:53.193069Z",
     "shell.execute_reply": "2024-08-29T05:36:53.192109Z",
     "shell.execute_reply.started": "2024-08-29T05:36:53.176729Z"
    }
   },
   "outputs": [],
   "source": [
    "class NetS(nn.Module):\n",
    "        def __init__(self):\n",
    "            super(NetS, self).__init__()\n",
    "            self.conv1 = nn.Conv2d(1, 32, 3, 1)\n",
    "            self.conv2 = nn.Conv2d(32, 64, 3, 1)\n",
    "            self.fc1 = nn.Linear(12544, 128)\n",
    "            self.fc2 = nn.Linear(128, 10)\n",
    "            self.bn1 = nn.BatchNorm2d(32)\n",
    "            self.bn2 = nn.BatchNorm2d(64)\n",
    "    \n",
    "        def forward(self, x):\n",
    "            x = F.relu(self.conv1(x))\n",
    "            x = self.bn1(x)\n",
    "            x = F.relu(self.conv2(x))\n",
    "            x = self.bn2(x)\n",
    "            x = F.max_pool2d(x, 2)\n",
    "            x = torch.flatten(x, 1)\n",
    "            x = F.relu(self.fc1(x))\n",
    "            x = self.fc2(x)\n",
    "            return x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "5badb174-6c13-4dcb-b728-bffee591fec3",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-08-29T05:36:53.193069Z",
     "iopub.status.busy": "2024-08-29T05:36:53.193069Z",
     "iopub.status.idle": "2024-08-29T05:36:53.207708Z",
     "shell.execute_reply": "2024-08-29T05:36:53.207708Z",
     "shell.execute_reply.started": "2024-08-29T05:36:53.193069Z"
    }
   },
   "outputs": [],
   "source": [
    "def get_victim_clone(args):\n",
    "    \n",
    "    student = NetS().to(args.device)\n",
    "    victim = torch.load(args.victim_path, map_location=args.device)\n",
    "    return victim , student"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b0f7b72a-4a58-4a63-9dd1-db77d69bafec",
   "metadata": {},
   "source": [
    "### Utilites"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "a72d70bf-5c0f-4601-a990-44ceaa0ae003",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-08-29T05:36:53.209914Z",
     "iopub.status.busy": "2024-08-29T05:36:53.209708Z",
     "iopub.status.idle": "2024-08-29T05:36:53.226327Z",
     "shell.execute_reply": "2024-08-29T05:36:53.225317Z",
     "shell.execute_reply.started": "2024-08-29T05:36:53.209914Z"
    }
   },
   "outputs": [],
   "source": [
    "class Args:\n",
    "    def __init__(self, device, seed, epochs, batch_size,num_timesteps, img_n, img_c, momentum,\n",
    "                 img_w, img_h, lr_G, lr_C, lr_hee, lr_z, weight_decay, N_G, N_C, \n",
    "                 steps_hee, grad_accumulation_steps, std_aug, lam, label_smooth_factor,\n",
    "                 victim_path, N_classes, debug, save_dir):\n",
    "        \n",
    "        self.device = device\n",
    "        self.seed = seed\n",
    "        self.epochs = epochs\n",
    "        self.batch_size = batch_size\n",
    "        self.num_timesteps = num_timesteps\n",
    "        self.img_n = img_n\n",
    "        self.img_c = img_c\n",
    "        self.img_w = img_w\n",
    "        self.img_h = img_h\n",
    "        self.lr_G = lr_G\n",
    "        self.lr_C = lr_C\n",
    "        self.lr_hee = lr_hee\n",
    "        self.lr_z = lr_z\n",
    "        self.weight_decay = weight_decay\n",
    "        self.momentum = momentum\n",
    "        self.N_G = N_G\n",
    "        self.N_C = N_C\n",
    "        self.steps_hee = steps_hee\n",
    "        self.grad_accumulation_steps = grad_accumulation_steps\n",
    "        self.std_aug = std_aug\n",
    "        self.lam = lam\n",
    "        self.victim_path = victim_path\n",
    "        self.N_classes = N_classes\n",
    "        self.debug = debug\n",
    "        self.victim_path = victim_path\n",
    "        self.label_smooth_factor = label_smooth_factor\n",
    "        self.save_dir = save_dir"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "3acc036a-a271-4620-a5ba-22c104ac0b49",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-08-29T05:36:53.226435Z",
     "iopub.status.busy": "2024-08-29T05:36:53.226435Z",
     "iopub.status.idle": "2024-08-29T05:36:53.242885Z",
     "shell.execute_reply": "2024-08-29T05:36:53.241875Z",
     "shell.execute_reply.started": "2024-08-29T05:36:53.226435Z"
    }
   },
   "outputs": [],
   "source": [
    "class FakeDataset(torch.utils.data.Dataset):\n",
    "    \"\"\"Some Information about FakeDataset\"\"\"\n",
    "\n",
    "    def __init__(self, root=\"\", transform=None):\n",
    "        super(FakeDataset, self).__init__()\n",
    "\n",
    "        self.transform = transform\n",
    "\n",
    "        history_images = np.load(os.path.join(root, \"fake_images.npy\"))\n",
    "        self.images = torch.from_numpy(history_images)\n",
    "\n",
    "    def __getitem__(self, index):\n",
    "        image = self.images[index]\n",
    "\n",
    "        return image\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.images)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "5dbcf080-786f-4378-8e0f-719bc6240b7f",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-08-29T05:36:53.242941Z",
     "iopub.status.busy": "2024-08-29T05:36:53.242941Z",
     "iopub.status.idle": "2024-08-29T05:36:53.257613Z",
     "shell.execute_reply": "2024-08-29T05:36:53.257613Z",
     "shell.execute_reply.started": "2024-08-29T05:36:53.242941Z"
    }
   },
   "outputs": [],
   "source": [
    "class TensorDataset(Dataset):\n",
    "    def __init__(self, tensor):\n",
    "        self.tensor = tensor\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.tensor)\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        return self.tensor[idx]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "90760983-d005-439a-b334-28565629571a",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-08-29T05:36:53.259970Z",
     "iopub.status.busy": "2024-08-29T05:36:53.259622Z",
     "iopub.status.idle": "2024-08-29T05:36:53.275117Z",
     "shell.execute_reply": "2024-08-29T05:36:53.275117Z",
     "shell.execute_reply.started": "2024-08-29T05:36:53.259970Z"
    }
   },
   "outputs": [],
   "source": [
    "class DataIter(object):\n",
    "    def __init__(self, dataloader):\n",
    "        self.dataloader = dataloader\n",
    "        self._iter = iter(self.dataloader)\n",
    "\n",
    "    def next(self):\n",
    "        try:\n",
    "            data = next(self._iter)\n",
    "        except StopIteration:\n",
    "            self._iter = iter(self.dataloader)\n",
    "            data = next(self._iter)\n",
    "        return data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "283f433e-1666-439c-9120-40ab921109ad",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-08-29T05:36:53.276326Z",
     "iopub.status.busy": "2024-08-29T05:36:53.276326Z",
     "iopub.status.idle": "2024-08-29T05:36:53.292896Z",
     "shell.execute_reply": "2024-08-29T05:36:53.291824Z",
     "shell.execute_reply.started": "2024-08-29T05:36:53.276326Z"
    }
   },
   "outputs": [],
   "source": [
    "def get_standard_augment(img_w, img_h):\n",
    "    std_aug = augmentation.container.ImageSequential(\n",
    "    augmentation.RandomCrop(size=[img_w, img_h], padding=4),\n",
    "    augmentation.RandomHorizontalFlip(),\n",
    ")\n",
    "    return std_aug"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "5bc23b46-cae7-4f8a-a471-986e7a97d28e",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-08-29T05:36:53.292896Z",
     "iopub.status.busy": "2024-08-29T05:36:53.292896Z",
     "iopub.status.idle": "2024-08-29T05:36:53.308473Z",
     "shell.execute_reply": "2024-08-29T05:36:53.307466Z",
     "shell.execute_reply.started": "2024-08-29T05:36:53.292896Z"
    }
   },
   "outputs": [],
   "source": [
    "def strong_aug(image):\n",
    "    device = image.device\n",
    "    image = TF.center_crop(\n",
    "        image,\n",
    "        [int(32.0 * random.uniform(0.95, 1.0)), int(32.0 * random.uniform(0.95, 1.0))],\n",
    "    )\n",
    "    image = TF.resize(image, [32, 32])\n",
    "    noise = torch.randn_like(image).to(device) * 0.001\n",
    "    image = torch.clamp(image + noise, 0.0, 1.0)\n",
    "    if random.uniform(0, 1) > 0.5:\n",
    "        image = TF.vflip(image)\n",
    "    if random.uniform(0, 1) > 0.5:\n",
    "        image = TF.hflip(image)\n",
    "    angles = [-15, 0, 15]\n",
    "    angle = random.choice(angles)\n",
    "    image = TF.rotate(image, angle)\n",
    "    return image"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "41ea93c1-1fec-4a94-bba0-fe084544b740",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-08-29T05:36:53.309848Z",
     "iopub.status.busy": "2024-08-29T05:36:53.309474Z",
     "iopub.status.idle": "2024-08-29T05:36:53.326209Z",
     "shell.execute_reply": "2024-08-29T05:36:53.325212Z",
     "shell.execute_reply.started": "2024-08-29T05:36:53.309848Z"
    }
   },
   "outputs": [],
   "source": [
    "def smooth_one_hot(args, true_labels):\n",
    "    \"\"\"\n",
    "    if smoothing == 0, it's one-hot method\n",
    "    if 0 < smoothing < 1, it's smooth method\n",
    "    \"\"\"\n",
    "    device = true_labels.device\n",
    "    true_labels = torch.nn.functional.one_hot(true_labels, args.N_classes).detach().cpu()\n",
    "    assert 0 <= args.label_smooth_factor < 1\n",
    "    confidence = 1.0 - args.label_smooth_factor\n",
    "    label_shape = torch.Size((true_labels.size(0), args.N_classes))\n",
    "    with torch.no_grad():\n",
    "        true_dist = torch.empty(size=label_shape, device=true_labels.device)\n",
    "        true_dist.fill_(args.label_smooth_factor / (args.N_classes - 1))\n",
    "        _, index = torch.max(true_labels, 1)\n",
    "\n",
    "        true_dist.scatter_(1, torch.LongTensor(index.unsqueeze(1)), confidence)\n",
    "    return true_dist.to(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "c27ac394-f91a-4698-8a3a-ad5f3c5c0819",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-08-29T05:36:53.327511Z",
     "iopub.status.busy": "2024-08-29T05:36:53.326512Z",
     "iopub.status.idle": "2024-08-29T05:36:53.344032Z",
     "shell.execute_reply": "2024-08-29T05:36:53.342775Z",
     "shell.execute_reply.started": "2024-08-29T05:36:53.327511Z"
    }
   },
   "outputs": [],
   "source": [
    "def evaluate(net, testloader):\n",
    "    correct = 0\n",
    "    total = 0\n",
    "    with torch.no_grad():\n",
    "        for data in testloader:\n",
    "            images, labels = data\n",
    "            outputs = net(images.to(device))\n",
    "            _, predicted = torch.max(outputs.data, 1)\n",
    "            total += labels.size(0)\n",
    "            correct += (predicted == labels.to(device)).sum().item()\n",
    "    \n",
    "    print(f'Accuracy of the network on the 10,000 test images: {100 * correct / total:.2f}%')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "eb7ce857-db53-4dfb-88ae-ea5e4324d282",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-08-29T05:36:53.346128Z",
     "iopub.status.busy": "2024-08-29T05:36:53.345029Z",
     "iopub.status.idle": "2024-08-29T05:36:53.354380Z",
     "shell.execute_reply": "2024-08-29T05:36:53.353897Z",
     "shell.execute_reply.started": "2024-08-29T05:36:53.346128Z"
    }
   },
   "outputs": [],
   "source": [
    "def save_batch_fake(args, images, epoch):\n",
    "    images = images.detach().cpu().numpy()\n",
    "    images_filename = os.path.join(args.save_dir, \"fake_images.npy\")\n",
    "\n",
    "    if epoch > 1:\n",
    "        org_images = np.load(images_filename)\n",
    "\n",
    "        images = np.concatenate((org_images, images), 0)\n",
    "\n",
    "    np.save(images_filename, images)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "75df346e-60d5-4525-bcd9-90e7065934d4",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-08-29T05:36:53.355844Z",
     "iopub.status.busy": "2024-08-29T05:36:53.354849Z",
     "iopub.status.idle": "2024-08-29T05:36:53.374613Z",
     "shell.execute_reply": "2024-08-29T05:36:53.374613Z",
     "shell.execute_reply.started": "2024-08-29T05:36:53.355844Z"
    }
   },
   "outputs": [],
   "source": [
    "# Function to calculate the Gram matrix\n",
    "def gram_matrix(x):\n",
    "    return torch.matmul(x, x.t())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "64d75aaf-ae69-479d-9483-32cacc82991c",
   "metadata": {},
   "source": [
    "### DFME++ Attack"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "fb06396f-c99b-47c5-b427-16cd013b2370",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-08-29T05:36:53.375720Z",
     "iopub.status.busy": "2024-08-29T05:36:53.375720Z",
     "iopub.status.idle": "2024-08-29T05:36:53.391671Z",
     "shell.execute_reply": "2024-08-29T05:36:53.390670Z",
     "shell.execute_reply.started": "2024-08-29T05:36:53.375720Z"
    }
   },
   "outputs": [],
   "source": [
    "# Loss function: L1 loss between student and teacher Gram matrices\n",
    "def l1_loss_between_grams(student_probs, teacher_probs):  # Student prob : time steps, classes. \n",
    "    student_gram = gram_matrix(student_probs)\n",
    "    teacher_gram = gram_matrix(teacher_probs)\n",
    "    return F.l1_loss(student_gram, teacher_gram)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "c2614f5c-9a4b-4441-b4f8-028b44634bed",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-08-29T05:36:53.393020Z",
     "iopub.status.busy": "2024-08-29T05:36:53.391671Z",
     "iopub.status.idle": "2024-08-29T05:36:53.408259Z",
     "shell.execute_reply": "2024-08-29T05:36:53.408259Z",
     "shell.execute_reply.started": "2024-08-29T05:36:53.393020Z"
    }
   },
   "outputs": [],
   "source": [
    "class Entropy_Loss(nn.Module):\n",
    "    def __init__(self, reduction=\"mean\"):\n",
    "        super(Entropy_Loss, self).__init__()\n",
    "        self.reduction = reduction\n",
    "\n",
    "    def forward(self, x):\n",
    "        b = F.softmax(x, dim=1) * F.log_softmax(x, dim=1)\n",
    "        b = -1.0 * b.sum(dim=1)\n",
    "        if self.reduction == \"mean\":\n",
    "            return b.mean()\n",
    "        elif self.reduction == \"sum\":\n",
    "            return b.sum()\n",
    "        elif self.reduction == \"none\":\n",
    "            return b"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "7ff5acd0-9e9c-4c65-87bd-ea4a366942b6",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-08-29T05:36:53.409334Z",
     "iopub.status.busy": "2024-08-29T05:36:53.409334Z",
     "iopub.status.idle": "2024-08-29T05:36:53.425945Z",
     "shell.execute_reply": "2024-08-29T05:36:53.424948Z",
     "shell.execute_reply.started": "2024-08-29T05:36:53.409334Z"
    }
   },
   "outputs": [],
   "source": [
    "def div_loss(outpus):\n",
    "    softmax_o_S = F.softmax(outpus, dim=1).mean(dim=0)\n",
    "    loss_div = (softmax_o_S * torch.log10(softmax_o_S)).sum()\n",
    "    return loss_div"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "f5abf25b-307f-4a83-bc46-fc8ce8b3136b",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-08-29T05:36:53.426566Z",
     "iopub.status.busy": "2024-08-29T05:36:53.426566Z",
     "iopub.status.idle": "2024-08-29T05:36:53.442653Z",
     "shell.execute_reply": "2024-08-29T05:36:53.441657Z",
     "shell.execute_reply.started": "2024-08-29T05:36:53.426566Z"
    }
   },
   "outputs": [],
   "source": [
    "def cross_entropy(outputs, smooth_labels):\n",
    "    loss = torch.nn.KLDivLoss(reduction=\"batchmean\")\n",
    "    return loss(F.log_softmax(outputs, dim=1), smooth_labels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "34ae25b1-adc2-4c90-b107-e5fe5d2dea5c",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-08-29T05:36:53.443247Z",
     "iopub.status.busy": "2024-08-29T05:36:53.443247Z",
     "iopub.status.idle": "2024-08-29T05:36:53.459429Z",
     "shell.execute_reply": "2024-08-29T05:36:53.458433Z",
     "shell.execute_reply.started": "2024-08-29T05:36:53.443247Z"
    }
   },
   "outputs": [],
   "source": [
    "def generate_hee(args, model, x):\n",
    "    model.eval()\n",
    "    x_hee = x.detach() + 0.001 * torch.torch.randn(x.shape).to(args.device).detach()\n",
    "    for _ in range(args.steps_hee):\n",
    "        x_hee.requires_grad_()\n",
    "        with torch.enable_grad():\n",
    "            pred = model(x_hee)\n",
    "            loss = Entropy_Loss(reduction=\"mean\")(pred)\n",
    "        grad = torch.autograd.grad(loss, [x_hee])[0] \n",
    "        x_hee = x_hee.detach() + args.lr_hee * torch.sign(grad.detach())\n",
    "        x_hee = torch.clamp(x_hee, 0.0, 1.0)\n",
    "    model.train()\n",
    "\n",
    "    return x_hee"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "24d8f970-f4a2-41c0-a3d5-0394941a31a0",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-08-29T05:36:53.459760Z",
     "iopub.status.busy": "2024-08-29T05:36:53.459760Z",
     "iopub.status.idle": "2024-08-29T05:36:53.474703Z",
     "shell.execute_reply": "2024-08-29T05:36:53.474703Z",
     "shell.execute_reply.started": "2024-08-29T05:36:53.459760Z"
    }
   },
   "outputs": [],
   "source": [
    "def train_generator(args, generator_model, clone_model, epoch):\n",
    "\n",
    "    generator_model.train()\n",
    "    clone_model.eval()\n",
    "    \n",
    "    best_fake = None\n",
    "    best_loss = 1e6\n",
    "    \n",
    "    if args.debug: print('Debug(train_generator) :-> Generating Images using Generator Model')\n",
    "    z = torch.randn(size=(args.img_n, args.img_c,args.img_w, args.img_h )).to(args.device)\n",
    "    z.requires_grad = True\n",
    "    \n",
    "    optimizer_G = torch.optim.Adam([{\"params\": generator_model.parameters()}, {\"params\": [z], \"lr\": args.lr_z}], lr=args.lr_G, betas=[0.5, 0.999])\n",
    "    pseudo_y = torch.randint(low=0, high=args.N_classes, size=(args.img_n,)).to(args.device)\n",
    "    soft_labels = smooth_one_hot(args, pseudo_y)\n",
    "    criterion = Entropy_Loss()\n",
    "    \n",
    "    if args.debug: print('Debug(train_generator) :-> Starting Generator Training')\n",
    "    for step in range(args.N_G):\n",
    "    \n",
    "        fake = torch.stack(generator_model(z)).squeeze(1)\n",
    "        aug_fake = args.std_aug(fake)\n",
    "        \n",
    "        logits = clone_model(aug_fake)\n",
    "        loss = criterion(logits)\n",
    "    \n",
    "    \n",
    "        with torch.no_grad():\n",
    "            if best_loss > loss.item() or best_fake is None:\n",
    "                best_loss = loss.item()\n",
    "                best_fake = fake\n",
    "        \n",
    "        optimizer_G.zero_grad()\n",
    "        loss.backward()\n",
    "        # torch.nn.utils.clip_grad_norm(clone_model.parameters(), max_norm = 1)\n",
    "        optimizer_G.step()\n",
    "    print(f\"Generator Step {step} average loss: {loss}\")\n",
    "    save_batch_fake(args, best_fake.data, epoch)\n",
    "    if args.debug: print('Debug(train_generator) :-> Generator Training Ended')\n",
    "    return generator_model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "39ca31e0-8315-459e-bc2b-f013c5091674",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-08-29T05:36:53.479033Z",
     "iopub.status.busy": "2024-08-29T05:36:53.479033Z",
     "iopub.status.idle": "2024-08-29T05:36:53.492484Z",
     "shell.execute_reply": "2024-08-29T05:36:53.491486Z",
     "shell.execute_reply.started": "2024-08-29T05:36:53.479033Z"
    }
   },
   "outputs": [],
   "source": [
    "def train_clone(args, generator_model, clone_model, victim_model, optimizer_C):\n",
    "\n",
    "    generator_model.eval()\n",
    "    clone_model.train()\n",
    "    victim_model.eval()\n",
    "    \n",
    "    dataset = FakeDataset(root=args.save_dir)\n",
    "    data_loader = torch.utils.data.DataLoader(\n",
    "        dataset,\n",
    "        batch_size=args.batch_size,\n",
    "        shuffle=True,\n",
    "    )\n",
    "    data_iter = DataIter(data_loader)\n",
    "    \n",
    "    victim_classes_fired = np.zeros(args.N_classes)\n",
    "    clone_classes_fired = np.zeros(args.N_classes)\n",
    "    losses = []\n",
    "    if args.debug: print('Debug(train_clone) :-> Starting Clone Model Training')        \n",
    "    for step in range(args.N_C):\n",
    "        fake = data_iter.next().to(args.device)\n",
    "        aug_fake = args.std_aug(fake)\n",
    "        # fake_hee = generate_hee(args, clone_model,strong_aug(aug_fake))\n",
    "        logits_T = victim_model(aug_fake).detach() \n",
    "        hard_labels = logits_T.topk(1, 1)[1].reshape(-1)\n",
    "        victim_probs = F.softmax(logits_T)\n",
    "        np.add.at(victim_classes_fired, hard_labels.cpu().numpy() , 1)\n",
    "        logits_C = clone_model(aug_fake)\n",
    "        clone_probs = F.softmax(logits_C)\n",
    "        np.add.at(clone_classes_fired, logits_C.topk(1, 1)[1].reshape(-1).cpu().numpy() , 1)\n",
    "        \n",
    "        loss = l1_loss_between_grams(clone_probs, victim_probs)\n",
    "        losses.append(loss.item())\n",
    "        optimizer_C.zero_grad()\n",
    "        loss.backward()\n",
    "        optimizer_C.step()\n",
    "        if step % 200 == 0:\n",
    "            print(f\"Clone Steps {step} average loss: {sum(losses[-len(data_loader):])/len(data_loader)}\")\n",
    "            print(f\"Clone Steps {step} Victim Classes Fired: {victim_classes_fired})\")\n",
    "            print(f\"Clone Steps {step} Clone Classes Fired: {clone_classes_fired})\")\n",
    "    if args.debug: print('Debug(train_clone) :-> Clone Model Training Ended') \n",
    "    return (generator_model, clone_model, victim_model, optimizer_C)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "9fb4a0d0-24b1-4475-b383-2091324cdc64",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-08-29T05:36:53.493105Z",
     "iopub.status.busy": "2024-08-29T05:36:53.493105Z",
     "iopub.status.idle": "2024-08-29T05:36:53.524472Z",
     "shell.execute_reply": "2024-08-29T05:36:53.524472Z",
     "shell.execute_reply.started": "2024-08-29T05:36:53.493105Z"
    }
   },
   "outputs": [],
   "source": [
    "debug = 1 #To debug code\n",
    "device = torch.device('cuda') #device placement cpu or gpu\n",
    "seed = 10 #seed for consistent result\n",
    "epochs = 10 #number of epochs to train\n",
    "batch_size = 256 #batchsize\n",
    "num_timesteps = 500 #timestamps in multistepgenerator\n",
    "img_n = 1 \n",
    "img_c = 1 #image channel\n",
    "img_w = 32 #image size\n",
    "img_h = 32 #image size\n",
    "lr_z = 0.01 #learning rate of latent code\n",
    "lr_G = 0.001 #learning rate of Generator\n",
    "lr_C = 0.01 #learing rate of clone model\n",
    "lr_hee = 0.03 #perturb number of steps\n",
    "weight_decay = 1e-4 #Optimizer parameter: decay's weight update\n",
    "momentum = 0.9 #Optimizer parameter: Remeber past information 1/momentum times\n",
    "N_G = 100 #Diffuser train steps\n",
    "N_C = 500 #Clone model steps \n",
    "steps_hee = 10 #number of epochs to train\n",
    "grad_accumulation_steps = 16 #update model after no.of steps\n",
    "std_aug = get_standard_augment(img_w, img_h) #standard augmentation: flip, crop\n",
    "lam = 0.009 #hyperparameter for balancing two loss terms in diffuser\n",
    "victim_path = \"HEE/fashion_mnist.pt\" #clone model path\n",
    "N_classes = 10 #No.of classes to predict\n",
    "label_smooth_factor = 0.2 #Hard to soft logits\n",
    "save_dir = r'Gen_Imgs\\LogOdds' #Folder to save genrator images"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "bf41408d-6de7-4bbe-b9fb-8c3e2e641a0c",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-08-29T05:36:53.525512Z",
     "iopub.status.busy": "2024-08-29T05:36:53.525512Z",
     "iopub.status.idle": "2024-08-29T05:36:53.541438Z",
     "shell.execute_reply": "2024-08-29T05:36:53.540438Z",
     "shell.execute_reply.started": "2024-08-29T05:36:53.525512Z"
    }
   },
   "outputs": [],
   "source": [
    "args = Args(\n",
    "        debug = debug,\n",
    "        device = device,\n",
    "        seed = seed,\n",
    "        epochs = epochs,\n",
    "        batch_size = batch_size,\n",
    "        num_timesteps = num_timesteps,\n",
    "        img_n = img_n,\n",
    "        img_c = img_c,\n",
    "        img_w = img_w,\n",
    "        img_h = img_h,\n",
    "        lr_G = lr_G,\n",
    "        lr_C = lr_C,\n",
    "        lr_z = lr_z,\n",
    "        lr_hee = lr_hee,\n",
    "        weight_decay = weight_decay,\n",
    "        momentum = momentum,\n",
    "        N_G = N_G,\n",
    "        N_C = N_C,\n",
    "        steps_hee = steps_hee,\n",
    "        grad_accumulation_steps = grad_accumulation_steps,\n",
    "        std_aug = std_aug,\n",
    "        lam = lam,\n",
    "        victim_path = victim_path,\n",
    "        N_classes = N_classes,\n",
    "        label_smooth_factor = label_smooth_factor,\n",
    "        save_dir = save_dir\n",
    "    )\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "1d587785-14be-4afe-a16a-f6b15b88d3f1",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-08-29T05:36:53.542435Z",
     "iopub.status.busy": "2024-08-29T05:36:53.542435Z",
     "iopub.status.idle": "2024-08-29T05:36:53.576393Z",
     "shell.execute_reply": "2024-08-29T05:36:53.576393Z",
     "shell.execute_reply.started": "2024-08-29T05:36:53.542435Z"
    }
   },
   "outputs": [],
   "source": [
    "torch.manual_seed(args.seed)\n",
    "torch.cuda.manual_seed(args.seed)\n",
    "torch.backends.cudnn.deterministic = True\n",
    "torch.backends.cudnn.benchmark = False"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "84d79aed-b9c5-4f0a-ab98-646d8c2a7fe6",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-08-29T05:36:53.578898Z",
     "iopub.status.busy": "2024-08-29T05:36:53.576393Z",
     "iopub.status.idle": "2024-08-29T05:36:53.990848Z",
     "shell.execute_reply": "2024-08-29T05:36:53.989848Z",
     "shell.execute_reply.started": "2024-08-29T05:36:53.576393Z"
    },
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "generator_model =  get_generator(args)\n",
    "victim_model, clone_model = get_victim_clone(args)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "18130477-043a-4282-ace6-554523132498",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-08-29T05:36:53.991850Z",
     "iopub.status.busy": "2024-08-29T05:36:53.991850Z",
     "iopub.status.idle": "2024-08-29T05:36:54.025717Z",
     "shell.execute_reply": "2024-08-29T05:36:54.025717Z",
     "shell.execute_reply.started": "2024-08-29T05:36:53.991850Z"
    }
   },
   "outputs": [],
   "source": [
    "optimizer_C = torch.optim.AdamW(\n",
    "        clone_model.parameters(),\n",
    "        lr=args.lr_C,\n",
    "        weight_decay=args.weight_decay,\n",
    "    )\n",
    "scheduler_lr = torch.optim.lr_scheduler.CosineAnnealingLR(\n",
    "    optimizer_C, args.epochs, eta_min=2e-4\n",
    ")\n",
    "transform = transforms.Compose([transforms.ToTensor(), transforms.Resize((32, 32))])\n",
    "testset = torchvision.datasets.FashionMNIST(root='./data', train=False, download=True, transform=transform)\n",
    "testloader = DataLoader(testset, batch_size=32, shuffle=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "5f35c1fa-02e1-49c6-90cf-3527b91e0510",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-08-29T05:36:54.025717Z",
     "iopub.status.busy": "2024-08-29T05:36:54.025717Z",
     "iopub.status.idle": "2024-08-29T05:36:58.764494Z",
     "shell.execute_reply": "2024-08-29T05:36:58.764494Z",
     "shell.execute_reply.started": "2024-08-29T05:36:54.025717Z"
    },
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy of the network on the 10,000 test images: 92.07%\n",
      "Accuracy of the network on the 10,000 test images: 7.63%\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "(None, None)"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "evaluate(victim_model, testloader), evaluate(clone_model, testloader)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5cd7e96c-9df4-4f02-a4db-21fcfca02c6b",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-08-29T05:36:58.767200Z",
     "iopub.status.busy": "2024-08-29T05:36:58.767200Z"
    },
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|                                                                                           | 0/10 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Debug(train_generator) :-> Generating Images using Generator Model\n",
      "Debug(train_generator) :-> Starting Generator Training\n"
     ]
    }
   ],
   "source": [
    " for epoch in tqdm(range(1, args.epochs + 1)):\n",
    "     \n",
    "    generator_model = train_generator(args, generator_model, clone_model, epoch)\n",
    "    print('-'*50)\n",
    "    generator_model, clone_model, victim_model, optimizer_C = train_clone(args, generator_model, clone_model, victim_model, optimizer_C)\n",
    "    print('-'*50)\n",
    "    print(scheduler_lr.get_last_lr())\n",
    "    print()\n",
    "    evaluate(clone_model, testloader)\n",
    "    print()\n",
    "    scheduler_lr.step()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3c8bb994-3d88-48ad-bdba-5f0ff252be97",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "torch22",
   "language": "python",
   "name": "torch22"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.14"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}

{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "209a4dd9-14d1-450b-8762-db36db43ef07",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-08-14T07:09:51.932218Z",
     "iopub.status.busy": "2024-08-14T07:09:51.932218Z",
     "iopub.status.idle": "2024-08-14T07:10:06.308143Z",
     "shell.execute_reply": "2024-08-14T07:10:06.308143Z",
     "shell.execute_reply.started": "2024-08-14T07:09:51.932218Z"
    }
   },
   "outputs": [],
   "source": [
    "import os\n",
    "import torch\n",
    "import random\n",
    "import warnings\n",
    "import numpy as np\n",
    "import torchvision\n",
    "import torch.nn as nn\n",
    "from tqdm import tqdm\n",
    "from copy import deepcopy\n",
    "from kornia import augmentation\n",
    "import torch.nn.functional as F\n",
    "import matplotlib.pyplot as plt\n",
    "from diffusers import UNet2DModel\n",
    "from datasets import load_dataset\n",
    "from torchvision import transforms\n",
    "from diffusers import DDPMScheduler\n",
    "from PIL import ImageDraw, ImageFont, Image\n",
    "from datasets import load_dataset, load_metric\n",
    "import torchvision.transforms.functional as TF\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "warnings.filterwarnings(\"ignore\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f1a83a42-7fa1-4069-a5ab-de1a26b60fbe",
   "metadata": {},
   "source": [
    "### Define Generator, Victim and Stolen"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "0c002cc9-5599-440c-81a0-abe667f37c95",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-08-14T07:10:06.308143Z",
     "iopub.status.busy": "2024-08-14T07:10:06.308143Z",
     "iopub.status.idle": "2024-08-14T07:10:06.341064Z",
     "shell.execute_reply": "2024-08-14T07:10:06.340087Z",
     "shell.execute_reply.started": "2024-08-14T07:10:06.308143Z"
    }
   },
   "outputs": [],
   "source": [
    "def get_generator(args):\n",
    "    class Flatten(nn.Module):\n",
    "        def __init__(self):\n",
    "            super(Flatten, self).__init__()\n",
    "    \n",
    "        def forward(self, x):\n",
    "            return torch.flatten(x, 1)\n",
    "    \n",
    "    \n",
    "    class Generator(nn.Module):\n",
    "        def __init__(self, nz=100, ngf=64, img_size=32, nc=3):\n",
    "            super(Generator, self).__init__()\n",
    "            self.params = (nz, ngf, img_size, nc)\n",
    "            self.init_size = img_size // 4\n",
    "            self.l1 = nn.Sequential(nn.Linear(nz, ngf * 2 * self.init_size ** 2))\n",
    "    \n",
    "            self.conv_blocks = nn.Sequential(\n",
    "                nn.BatchNorm2d(ngf * 2),\n",
    "                nn.Upsample(scale_factor=2),\n",
    "    \n",
    "                nn.Conv2d(ngf * 2, ngf * 2, 3, stride=1, padding=1, bias=False),\n",
    "                nn.BatchNorm2d(ngf * 2),\n",
    "                nn.LeakyReLU(0.2, inplace=True),\n",
    "                nn.Upsample(scale_factor=2),\n",
    "    \n",
    "                nn.Conv2d(ngf * 2, ngf, 3, stride=1, padding=1, bias=False),\n",
    "                nn.BatchNorm2d(ngf),\n",
    "                nn.LeakyReLU(0.2, inplace=True),\n",
    "                nn.Conv2d(ngf, nc, 3, stride=1, padding=1),\n",
    "                nn.Sigmoid(),\n",
    "            )\n",
    "    \n",
    "        def forward(self, z):\n",
    "            out = self.l1(z)\n",
    "            out = out.view(out.shape[0], -1, self.init_size, self.init_size)\n",
    "            img = self.conv_blocks(out)\n",
    "            return img\n",
    "    \n",
    "        # return a copy of its own\n",
    "        def clone(self):\n",
    "            clone = Generator(self.params[0], self.params[1], self.params[2], self.params[3])\n",
    "            clone.load_state_dict(self.state_dict())\n",
    "            return clone.cuda()\n",
    "\n",
    "    return Generator(nz=args.gen_dim_z, ngf=64, img_size=args.img_w, nc=args.img_c).to(args.device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "58c1448a-87e0-4758-b630-61a68a8e2a7f",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-08-14T07:10:06.343083Z",
     "iopub.status.busy": "2024-08-14T07:10:06.342062Z",
     "iopub.status.idle": "2024-08-14T07:10:06.356672Z",
     "shell.execute_reply": "2024-08-14T07:10:06.355663Z",
     "shell.execute_reply.started": "2024-08-14T07:10:06.343083Z"
    }
   },
   "outputs": [],
   "source": [
    "class Net(nn.Module):\n",
    "        def __init__(self):\n",
    "            super(Net, self).__init__()\n",
    "            self.conv1 = nn.Conv2d(1, 32, 3, 1)\n",
    "            self.conv2 = nn.Conv2d(32, 64, 3, 1)\n",
    "            self.fc1 = nn.Linear(12544, 128)\n",
    "            self.fc2 = nn.Linear(128, 10)\n",
    "    \n",
    "        def forward(self, x):\n",
    "            x = F.relu(self.conv1(x))\n",
    "            x = F.relu(self.conv2(x))\n",
    "            x = F.max_pool2d(x, 2)\n",
    "            x = torch.flatten(x, 1)\n",
    "            x = F.relu(self.fc1(x))\n",
    "            x = self.fc2(x)\n",
    "            return x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "c5bd5968-5922-4035-bfa2-75a3572b11c3",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-08-14T07:10:06.357274Z",
     "iopub.status.busy": "2024-08-14T07:10:06.357274Z",
     "iopub.status.idle": "2024-08-14T07:10:06.373267Z",
     "shell.execute_reply": "2024-08-14T07:10:06.372263Z",
     "shell.execute_reply.started": "2024-08-14T07:10:06.357274Z"
    }
   },
   "outputs": [],
   "source": [
    "class NetS(nn.Module):\n",
    "        def __init__(self):\n",
    "            super(NetS, self).__init__()\n",
    "            self.conv1 = nn.Conv2d(1, 32, 3, 1)\n",
    "            self.conv2 = nn.Conv2d(32, 64, 3, 1)\n",
    "            self.fc1 = nn.Linear(12544, 128)\n",
    "            self.fc2 = nn.Linear(128, 10)\n",
    "            self.bn1 = nn.BatchNorm2d(32)\n",
    "            self.bn2 = nn.BatchNorm2d(64)\n",
    "    \n",
    "        def forward(self, x):\n",
    "            x = F.relu(self.conv1(x))\n",
    "            x = self.bn1(x)\n",
    "            x = F.relu(self.conv2(x))\n",
    "            x = self.bn2(x)\n",
    "            x = F.max_pool2d(x, 2)\n",
    "            x = torch.flatten(x, 1)\n",
    "            x = F.relu(self.fc1(x))\n",
    "            x = self.fc2(x)\n",
    "            return x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "5badb174-6c13-4dcb-b728-bffee591fec3",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-08-14T07:10:06.374658Z",
     "iopub.status.busy": "2024-08-14T07:10:06.374658Z",
     "iopub.status.idle": "2024-08-14T07:10:06.390931Z",
     "shell.execute_reply": "2024-08-14T07:10:06.389930Z",
     "shell.execute_reply.started": "2024-08-14T07:10:06.374658Z"
    }
   },
   "outputs": [],
   "source": [
    "def get_victim_clone(args):\n",
    "    \n",
    "    student = NetS().to(args.device)\n",
    "    victim = torch.load(args.victim_path, map_location=args.device)\n",
    "    return victim , student"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b0f7b72a-4a58-4a63-9dd1-db77d69bafec",
   "metadata": {},
   "source": [
    "### Utilites"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "a72d70bf-5c0f-4601-a990-44ceaa0ae003",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-08-14T07:10:06.392032Z",
     "iopub.status.busy": "2024-08-14T07:10:06.392032Z",
     "iopub.status.idle": "2024-08-14T07:10:06.405388Z",
     "shell.execute_reply": "2024-08-14T07:10:06.404384Z",
     "shell.execute_reply.started": "2024-08-14T07:10:06.392032Z"
    }
   },
   "outputs": [],
   "source": [
    "class Args:\n",
    "    def __init__(self, device, seed, epochs, batch_size, img_n, img_c, momentum,\n",
    "                 img_w, img_h, lr_G, lr_C, lr_hee, lr_z, weight_decay, N_G, N_C, \n",
    "                 steps_hee, grad_accumulation_steps, std_aug, lam, label_smooth_factor,\n",
    "                 victim_path, N_classes, debug, gen_dim_z, save_dir):\n",
    "        \n",
    "        self.device = device\n",
    "        self.seed = seed\n",
    "        self.epochs = epochs\n",
    "        self.batch_size = batch_size\n",
    "        self.img_n = img_n\n",
    "        self.img_c = img_c\n",
    "        self.img_w = img_w\n",
    "        self.img_h = img_h\n",
    "        self.lr_G = lr_G\n",
    "        self.lr_C = lr_C\n",
    "        self.lr_hee = lr_hee\n",
    "        self.lr_z = lr_z\n",
    "        self.weight_decay = weight_decay\n",
    "        self.momentum = momentum\n",
    "        self.N_G = N_G\n",
    "        self.N_C = N_C\n",
    "        self.steps_hee = steps_hee\n",
    "        self.grad_accumulation_steps = grad_accumulation_steps\n",
    "        self.std_aug = std_aug\n",
    "        self.lam = lam\n",
    "        self.victim_path = victim_path\n",
    "        self.N_classes = N_classes\n",
    "        self.debug = debug\n",
    "        self.victim_path = victim_path\n",
    "        self.gen_dim_z = gen_dim_z\n",
    "        self.label_smooth_factor = label_smooth_factor\n",
    "        self.save_dir = save_dir"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "3acc036a-a271-4620-a5ba-22c104ac0b49",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-08-14T07:10:06.407392Z",
     "iopub.status.busy": "2024-08-14T07:10:06.406399Z",
     "iopub.status.idle": "2024-08-14T07:10:06.424574Z",
     "shell.execute_reply": "2024-08-14T07:10:06.423958Z",
     "shell.execute_reply.started": "2024-08-14T07:10:06.407392Z"
    }
   },
   "outputs": [],
   "source": [
    "class FakeDataset(torch.utils.data.Dataset):\n",
    "    \"\"\"Some Information about FakeDataset\"\"\"\n",
    "\n",
    "    def __init__(self, root=\"\", transform=None):\n",
    "        super(FakeDataset, self).__init__()\n",
    "\n",
    "        self.transform = transform\n",
    "\n",
    "        history_images = np.load(os.path.join(root, \"fake_images.npy\"))\n",
    "        self.images = torch.from_numpy(history_images)\n",
    "\n",
    "    def __getitem__(self, index):\n",
    "        image = self.images[index]\n",
    "\n",
    "        return image\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.images)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "5dbcf080-786f-4378-8e0f-719bc6240b7f",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-08-14T07:10:06.424574Z",
     "iopub.status.busy": "2024-08-14T07:10:06.424574Z",
     "iopub.status.idle": "2024-08-14T07:10:06.440676Z",
     "shell.execute_reply": "2024-08-14T07:10:06.439682Z",
     "shell.execute_reply.started": "2024-08-14T07:10:06.424574Z"
    }
   },
   "outputs": [],
   "source": [
    "class TensorDataset(Dataset):\n",
    "    def __init__(self, tensor):\n",
    "        self.tensor = tensor\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.tensor)\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        return self.tensor[idx]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "90760983-d005-439a-b334-28565629571a",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-08-14T07:10:06.441227Z",
     "iopub.status.busy": "2024-08-14T07:10:06.441227Z",
     "iopub.status.idle": "2024-08-14T07:10:06.457341Z",
     "shell.execute_reply": "2024-08-14T07:10:06.456339Z",
     "shell.execute_reply.started": "2024-08-14T07:10:06.441227Z"
    }
   },
   "outputs": [],
   "source": [
    "class DataIter(object):\n",
    "    def __init__(self, dataloader):\n",
    "        self.dataloader = dataloader\n",
    "        self._iter = iter(self.dataloader)\n",
    "\n",
    "    def next(self):\n",
    "        try:\n",
    "            data = next(self._iter)\n",
    "        except StopIteration:\n",
    "            self._iter = iter(self.dataloader)\n",
    "            data = next(self._iter)\n",
    "        return data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "283f433e-1666-439c-9120-40ab921109ad",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-08-14T07:10:06.460343Z",
     "iopub.status.busy": "2024-08-14T07:10:06.460343Z",
     "iopub.status.idle": "2024-08-14T07:10:06.473924Z",
     "shell.execute_reply": "2024-08-14T07:10:06.473924Z",
     "shell.execute_reply.started": "2024-08-14T07:10:06.460343Z"
    }
   },
   "outputs": [],
   "source": [
    "def get_standard_augment(img_w, img_h):\n",
    "    std_aug = augmentation.container.ImageSequential(\n",
    "    augmentation.RandomCrop(size=[img_w, img_h], padding=4),\n",
    "    augmentation.RandomHorizontalFlip(),\n",
    ")\n",
    "    return std_aug"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "5bc23b46-cae7-4f8a-a471-986e7a97d28e",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-08-14T07:10:06.473924Z",
     "iopub.status.busy": "2024-08-14T07:10:06.473924Z",
     "iopub.status.idle": "2024-08-14T07:10:06.490641Z",
     "shell.execute_reply": "2024-08-14T07:10:06.488640Z",
     "shell.execute_reply.started": "2024-08-14T07:10:06.473924Z"
    }
   },
   "outputs": [],
   "source": [
    "def strong_aug(image):\n",
    "    device = image.device\n",
    "    image = TF.center_crop(\n",
    "        image,\n",
    "        [int(32.0 * random.uniform(0.95, 1.0)), int(32.0 * random.uniform(0.95, 1.0))],\n",
    "    )\n",
    "    image = TF.resize(image, [32, 32])\n",
    "    noise = torch.randn_like(image).to(device) * 0.001\n",
    "    image = torch.clamp(image + noise, 0.0, 1.0)\n",
    "    if random.uniform(0, 1) > 0.5:\n",
    "        image = TF.vflip(image)\n",
    "    if random.uniform(0, 1) > 0.5:\n",
    "        image = TF.hflip(image)\n",
    "    angles = [-15, 0, 15]\n",
    "    angle = random.choice(angles)\n",
    "    image = TF.rotate(image, angle)\n",
    "    return image"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "41ea93c1-1fec-4a94-bba0-fe084544b740",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-08-14T07:10:06.491929Z",
     "iopub.status.busy": "2024-08-14T07:10:06.491929Z",
     "iopub.status.idle": "2024-08-14T07:10:06.507581Z",
     "shell.execute_reply": "2024-08-14T07:10:06.507136Z",
     "shell.execute_reply.started": "2024-08-14T07:10:06.491929Z"
    }
   },
   "outputs": [],
   "source": [
    "def smooth_one_hot(args, true_labels):\n",
    "    \"\"\"\n",
    "    if smoothing == 0, it's one-hot method\n",
    "    if 0 < smoothing < 1, it's smooth method\n",
    "    \"\"\"\n",
    "    device = true_labels.device\n",
    "    true_labels = torch.nn.functional.one_hot(true_labels, args.N_classes).detach().cpu()\n",
    "    assert 0 <= args.label_smooth_factor < 1\n",
    "    confidence = 1.0 - args.label_smooth_factor\n",
    "    label_shape = torch.Size((true_labels.size(0), args.N_classes))\n",
    "    with torch.no_grad():\n",
    "        true_dist = torch.empty(size=label_shape, device=true_labels.device)\n",
    "        true_dist.fill_(args.label_smooth_factor / (args.N_classes - 1))\n",
    "        _, index = torch.max(true_labels, 1)\n",
    "\n",
    "        true_dist.scatter_(1, torch.LongTensor(index.unsqueeze(1)), confidence)\n",
    "    return true_dist.to(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "c27ac394-f91a-4698-8a3a-ad5f3c5c0819",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-08-14T07:10:06.507581Z",
     "iopub.status.busy": "2024-08-14T07:10:06.507581Z",
     "iopub.status.idle": "2024-08-14T07:10:06.523826Z",
     "shell.execute_reply": "2024-08-14T07:10:06.522830Z",
     "shell.execute_reply.started": "2024-08-14T07:10:06.507581Z"
    }
   },
   "outputs": [],
   "source": [
    "def evaluate(net, testloader):\n",
    "    correct = 0\n",
    "    total = 0\n",
    "    with torch.no_grad():\n",
    "        for data in testloader:\n",
    "            images, labels = data\n",
    "            outputs = net(images.to(device))\n",
    "            _, predicted = torch.max(outputs.data, 1)\n",
    "            total += labels.size(0)\n",
    "            correct += (predicted == labels.to(device)).sum().item()\n",
    "    \n",
    "    print(f'Accuracy of the network on the 10,000 test images: {100 * correct / total:.2f}%')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "eb7ce857-db53-4dfb-88ae-ea5e4324d282",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-08-14T07:10:06.524958Z",
     "iopub.status.busy": "2024-08-14T07:10:06.524958Z",
     "iopub.status.idle": "2024-08-14T07:10:06.530742Z",
     "shell.execute_reply": "2024-08-14T07:10:06.530742Z",
     "shell.execute_reply.started": "2024-08-14T07:10:06.524958Z"
    }
   },
   "outputs": [],
   "source": [
    "def save_batch_fake(args, images, epoch):\n",
    "    images = images.detach().cpu().numpy()\n",
    "    images_filename = os.path.join(args.save_dir, \"fake_images.npy\")\n",
    "\n",
    "    if epoch > 1:\n",
    "        org_images = np.load(images_filename)\n",
    "\n",
    "        images = np.concatenate((org_images, images), 0)\n",
    "\n",
    "    np.save(images_filename, images)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "64d75aaf-ae69-479d-9483-32cacc82991c",
   "metadata": {},
   "source": [
    "### DFME++ Attack"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "c2614f5c-9a4b-4441-b4f8-028b44634bed",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-08-14T07:10:06.532810Z",
     "iopub.status.busy": "2024-08-14T07:10:06.531799Z",
     "iopub.status.idle": "2024-08-14T07:10:06.541743Z",
     "shell.execute_reply": "2024-08-14T07:10:06.541743Z",
     "shell.execute_reply.started": "2024-08-14T07:10:06.532810Z"
    }
   },
   "outputs": [],
   "source": [
    "class Entropy_Loss(nn.Module):\n",
    "    def __init__(self, reduction=\"mean\"):\n",
    "        super(Entropy_Loss, self).__init__()\n",
    "        self.reduction = reduction\n",
    "\n",
    "    def forward(self, x):\n",
    "        b = F.softmax(x, dim=1) * F.log_softmax(x, dim=1)\n",
    "        b = -1.0 * b.sum(dim=1)\n",
    "        if self.reduction == \"mean\":\n",
    "            return b.mean()\n",
    "        elif self.reduction == \"sum\":\n",
    "            return b.sum()\n",
    "        elif self.reduction == \"none\":\n",
    "            return b"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "3a686e71-ba43-4e9c-b036-8575c8b02554",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-08-14T07:10:06.541743Z",
     "iopub.status.busy": "2024-08-14T07:10:06.541743Z",
     "iopub.status.idle": "2024-08-14T07:10:06.558207Z",
     "shell.execute_reply": "2024-08-14T07:10:06.557208Z",
     "shell.execute_reply.started": "2024-08-14T07:10:06.541743Z"
    }
   },
   "outputs": [],
   "source": [
    "def logodds(logits):\n",
    "    eps = 1e-7\n",
    "    softmax_odds = F.softmax(logits, dim=1)\n",
    "    softmax_odds = torch.clamp(softmax_odds, min = eps, max = 1-eps)\n",
    "    log_odd = torch.log((softmax_odds) / (1-softmax_odds) )\n",
    "    log_sigmoid_odd = torch.nn.LogSigmoid()\n",
    "    return -log_sigmoid_odd(log_odd).sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "f5abf25b-307f-4a83-bc46-fc8ce8b3136b",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-08-14T07:10:06.558207Z",
     "iopub.status.busy": "2024-08-14T07:10:06.558207Z",
     "iopub.status.idle": "2024-08-14T07:10:06.574067Z",
     "shell.execute_reply": "2024-08-14T07:10:06.573067Z",
     "shell.execute_reply.started": "2024-08-14T07:10:06.558207Z"
    }
   },
   "outputs": [],
   "source": [
    "def cross_entropy(outputs, smooth_labels):\n",
    "    loss = torch.nn.KLDivLoss(reduction=\"batchmean\")\n",
    "    return loss(F.log_softmax(outputs, dim=1), smooth_labels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "34ae25b1-adc2-4c90-b107-e5fe5d2dea5c",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-08-14T07:10:06.575063Z",
     "iopub.status.busy": "2024-08-14T07:10:06.575063Z",
     "iopub.status.idle": "2024-08-14T07:10:06.591344Z",
     "shell.execute_reply": "2024-08-14T07:10:06.590691Z",
     "shell.execute_reply.started": "2024-08-14T07:10:06.575063Z"
    }
   },
   "outputs": [],
   "source": [
    "def generate_hee(args, model, x):\n",
    "    model.eval()\n",
    "    x_hee = x.detach() + 0.001 * torch.torch.randn(x.shape).to(args.device).detach()\n",
    "    for _ in range(args.steps_hee):\n",
    "        x_hee.requires_grad_()\n",
    "        with torch.enable_grad():\n",
    "            pred = model(x_hee)\n",
    "            loss = Entropy_Loss(reduction=\"mean\")(pred)\n",
    "        grad = torch.autograd.grad(loss, [x_hee])[0] \n",
    "        x_hee = x_hee.detach() + args.lr_hee * torch.sign(grad.detach())\n",
    "        x_hee = torch.clamp(x_hee, 0.0, 1.0)\n",
    "    model.train()\n",
    "\n",
    "    return x_hee"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "964fc04d-4a02-4f44-9ff9-b8d8fce3d245",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-08-14T07:10:06.591344Z",
     "iopub.status.busy": "2024-08-14T07:10:06.591344Z",
     "iopub.status.idle": "2024-08-14T07:10:06.607124Z",
     "shell.execute_reply": "2024-08-14T07:10:06.606126Z",
     "shell.execute_reply.started": "2024-08-14T07:10:06.591344Z"
    }
   },
   "outputs": [],
   "source": [
    "def train_generator(args, generator_model, clone_model, epoch):\n",
    "\n",
    "    generator_model.train()\n",
    "    clone_model.eval()\n",
    "\n",
    "    best_fake = None\n",
    "    best_loss = 1e6\n",
    "    \n",
    "    if args.debug: print('Debug(train_generator) :-> Generating Images using Generator Model')\n",
    "    z = torch.randn(size=(args.img_n, args.gen_dim_z)).to(args.device)\n",
    "    z.requires_grad = True\n",
    "    \n",
    "    optimizer_G = torch.optim.Adam([{\"params\": generator_model.parameters()}, {\"params\": [z], \"lr\": args.lr_z}], lr=args.lr_G, betas=[0.5, 0.999])\n",
    "    pseudo_y = torch.randint(low=0, high=args.N_classes, size=(args.img_n,)).to(args.device)\n",
    "    soft_labels = smooth_one_hot(args, pseudo_y)\n",
    "    \n",
    "    if args.debug: print('Debug(train_generator) :-> Starting Generator Training')\n",
    "    for step in range(args.N_G):\n",
    "\n",
    "        fake = generator_model(z)\n",
    "        aug_fake = args.std_aug(fake)\n",
    "        \n",
    "        logits = clone_model(aug_fake)\n",
    "\n",
    "        loss_cls = cross_entropy(logits, soft_labels)\n",
    "        loss_logodd = logodds(logits)\n",
    "        loss = loss_logodd * args.lam\n",
    "\n",
    "        with torch.no_grad():\n",
    "            if best_loss > loss.item() or best_fake is None:\n",
    "                best_loss = loss.item()\n",
    "                best_fake = fake\n",
    "        \n",
    "        optimizer_G.zero_grad()\n",
    "        loss.backward()\n",
    "        # torch.nn.utils.clip_grad_norm(clone_model.parameters(), max_norm = 1)\n",
    "        optimizer_G.step()\n",
    "    print(f\"Generator Step {step} average loss: {loss}\")\n",
    "    save_batch_fake(args, best_fake.data, epoch)\n",
    "    if args.debug: print('Debug(train_generator) :-> Generator Training Ended')\n",
    "    return generator_model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "39ca31e0-8315-459e-bc2b-f013c5091674",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-08-14T07:10:06.608556Z",
     "iopub.status.busy": "2024-08-14T07:10:06.608556Z",
     "iopub.status.idle": "2024-08-14T07:10:06.624919Z",
     "shell.execute_reply": "2024-08-14T07:10:06.623950Z",
     "shell.execute_reply.started": "2024-08-14T07:10:06.608556Z"
    }
   },
   "outputs": [],
   "source": [
    "def train_clone(args, generator_model, clone_model, victim_model, optimizer_C):\n",
    "\n",
    "    generator_model.eval()\n",
    "    clone_model.train()\n",
    "    victim_model.eval()\n",
    "\n",
    "    dataset = FakeDataset(root=args.save_dir)\n",
    "    data_loader = torch.utils.data.DataLoader(\n",
    "        dataset,\n",
    "        batch_size=args.batch_size,\n",
    "        shuffle=True,\n",
    "    )\n",
    "    data_iter = DataIter(data_loader)\n",
    "\n",
    "    victim_classes_fired = np.zeros(args.N_classes)\n",
    "    clone_classes_fired = np.zeros(args.N_classes)\n",
    "    losses = []\n",
    "    if args.debug: print('Debug(train_clone) :-> Starting Clone Model Training')        \n",
    "    for step in range(args.N_C):\n",
    "        fake = data_iter.next().to(args.device)\n",
    "        aug_fake = args.std_aug(fake)\n",
    "        fake_hee = generate_hee(args, clone_model,strong_aug(aug_fake))\n",
    "        logits_T = victim_model(fake_hee).detach() \n",
    "        hard_labels = logits_T.topk(1, 1)[1].reshape(-1)\n",
    "        np.add.at(victim_classes_fired, hard_labels.cpu().numpy() , 1)\n",
    "        logits_C = clone_model(fake_hee)\n",
    "        np.add.at(clone_classes_fired, logits_C.topk(1, 1)[1].reshape(-1).cpu().numpy() , 1)\n",
    "        \n",
    "        loss = F.cross_entropy(logits_C, hard_labels)\n",
    "        losses.append(loss.item())\n",
    "        optimizer_C.zero_grad()\n",
    "        loss.backward()\n",
    "        optimizer_C.step()\n",
    "        if step % 200 == 0:\n",
    "            print(f\"Clone Steps {step} average loss: {sum(losses[-len(data_loader):])/len(data_loader)}\")\n",
    "            print(f\"Clone Steps {step} Victim Classes Fired: {victim_classes_fired})\")\n",
    "            print(f\"Clone Steps {step} Clone Classes Fired: {clone_classes_fired})\")\n",
    "    if args.debug: print('Debug(train_clone) :-> Clone Model Training Ended') \n",
    "    return (generator_model, clone_model, victim_model, optimizer_C)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "9fb4a0d0-24b1-4475-b383-2091324cdc64",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-08-14T07:10:06.624919Z",
     "iopub.status.busy": "2024-08-14T07:10:06.624919Z",
     "iopub.status.idle": "2024-08-14T07:10:06.640332Z",
     "shell.execute_reply": "2024-08-14T07:10:06.639340Z",
     "shell.execute_reply.started": "2024-08-14T07:10:06.624919Z"
    }
   },
   "outputs": [],
   "source": [
    "debug = 1 #To debug code\n",
    "device = torch.device('cuda') #device placement cpu or gpu\n",
    "seed = 10 #seed for consistent result\n",
    "epochs = 10 #number of epochs to train\n",
    "batch_size = 256 #per device batch size\n",
    "img_n = 256 #min(160, batch_size*10*2) #per epoch image generation count\n",
    "img_c = 1 #image channel\n",
    "img_w = 32 #image size\n",
    "img_h = 32 #image size\n",
    "lr_z = 0.01 #learning rate of latent code\n",
    "lr_G = 0.01 #learning rate of Generator\n",
    "lr_C = 0.09 #learing rate of clone model\n",
    "lr_hee = 0.03 #perturb number of steps\n",
    "weight_decay = 1e-4 #Optimizer parameter: decay's weight update\n",
    "momentum = 0.9 #Optimizer parameter: Remeber past information 1/momentum times\n",
    "N_G = 10 #Diffuser train steps\n",
    "N_C = 500 #Clone model steps \n",
    "steps_hee = 10 #number of epochs to train\n",
    "grad_accumulation_steps = 16 #update model after no.of steps\n",
    "std_aug = get_standard_augment(img_w, img_h) #standard augmentation: flip, crop\n",
    "lam = 0.009 #hyperparameter for balancing two loss terms in diffuser\n",
    "victim_path = \"HEE/fashion_mnist.pt\" #clone model path\n",
    "N_classes = 10 #No.of classes to predict\n",
    "gen_dim_z = 256 #Dimension of generator input noise\n",
    "label_smooth_factor = 0.2 #Hard to soft logits\n",
    "save_dir = r'Gen_Imgs\\LogOdds' #Folder to save genrator images"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "bf41408d-6de7-4bbe-b9fb-8c3e2e641a0c",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-08-14T07:10:06.641073Z",
     "iopub.status.busy": "2024-08-14T07:10:06.641073Z",
     "iopub.status.idle": "2024-08-14T07:10:06.657263Z",
     "shell.execute_reply": "2024-08-14T07:10:06.656261Z",
     "shell.execute_reply.started": "2024-08-14T07:10:06.641073Z"
    }
   },
   "outputs": [],
   "source": [
    "args = Args(\n",
    "        debug = debug,\n",
    "        device = device,\n",
    "        seed = seed,\n",
    "        epochs = epochs,\n",
    "        batch_size = batch_size,\n",
    "        img_n = img_n,\n",
    "        img_c = img_c,\n",
    "        img_w = img_w,\n",
    "        img_h = img_h,\n",
    "        lr_G = lr_G,\n",
    "        lr_C = lr_C,\n",
    "        lr_z = lr_z,\n",
    "        lr_hee = lr_hee,\n",
    "        weight_decay = weight_decay,\n",
    "        momentum = momentum,\n",
    "        N_G = N_G,\n",
    "        N_C = N_C,\n",
    "        steps_hee = steps_hee,\n",
    "        grad_accumulation_steps = grad_accumulation_steps,\n",
    "        std_aug = std_aug,\n",
    "        lam = lam,\n",
    "        victim_path = victim_path,\n",
    "        N_classes = N_classes,\n",
    "        label_smooth_factor = label_smooth_factor,\n",
    "        gen_dim_z = gen_dim_z,\n",
    "        save_dir = save_dir\n",
    "    )\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "1d587785-14be-4afe-a16a-f6b15b88d3f1",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-08-14T07:10:06.658258Z",
     "iopub.status.busy": "2024-08-14T07:10:06.658258Z",
     "iopub.status.idle": "2024-08-14T07:10:06.692678Z",
     "shell.execute_reply": "2024-08-14T07:10:06.691724Z",
     "shell.execute_reply.started": "2024-08-14T07:10:06.658258Z"
    }
   },
   "outputs": [],
   "source": [
    "torch.manual_seed(args.seed)\n",
    "torch.cuda.manual_seed(args.seed)\n",
    "torch.backends.cudnn.deterministic = True\n",
    "torch.backends.cudnn.benchmark = False"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "84d79aed-b9c5-4f0a-ab98-646d8c2a7fe6",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-08-14T07:10:06.693681Z",
     "iopub.status.busy": "2024-08-14T07:10:06.693681Z",
     "iopub.status.idle": "2024-08-14T07:10:06.889395Z",
     "shell.execute_reply": "2024-08-14T07:10:06.888122Z",
     "shell.execute_reply.started": "2024-08-14T07:10:06.693681Z"
    }
   },
   "outputs": [],
   "source": [
    "generator_model =  get_generator(args)\n",
    "victim_model, clone_model = get_victim_clone(args)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "18130477-043a-4282-ace6-554523132498",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-08-14T07:10:06.890396Z",
     "iopub.status.busy": "2024-08-14T07:10:06.890396Z",
     "iopub.status.idle": "2024-08-14T07:10:06.923781Z",
     "shell.execute_reply": "2024-08-14T07:10:06.923781Z",
     "shell.execute_reply.started": "2024-08-14T07:10:06.890396Z"
    }
   },
   "outputs": [],
   "source": [
    "optimizer_C = torch.optim.AdamW(\n",
    "        clone_model.parameters(),\n",
    "        lr=args.lr_C,\n",
    "        weight_decay=args.weight_decay,\n",
    "    )\n",
    "scheduler_lr = torch.optim.lr_scheduler.CosineAnnealingLR(\n",
    "    optimizer_C, args.epochs, eta_min=2e-4\n",
    ")\n",
    "transform = transforms.Compose([transforms.ToTensor(), transforms.Resize((32, 32))])\n",
    "testset = torchvision.datasets.FashionMNIST(root='./data', train=False, download=True, transform=transform)\n",
    "testloader = DataLoader(testset, batch_size=32, shuffle=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5f35c1fa-02e1-49c6-90cf-3527b91e0510",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "evaluate(victim_model, testloader), evaluate(clone_model, testloader)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "5cd7e96c-9df4-4f02-a4db-21fcfca02c6b",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-08-14T07:10:06.923781Z",
     "iopub.status.busy": "2024-08-14T07:10:06.923781Z",
     "iopub.status.idle": "2024-08-14T07:26:30.429619Z",
     "shell.execute_reply": "2024-08-14T07:26:30.429619Z",
     "shell.execute_reply.started": "2024-08-14T07:10:06.923781Z"
    },
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|                                                                                           | 0/10 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Debug(train_generator) :-> Generating Images using Generator Model\n",
      "Debug(train_generator) :-> Starting Generator Training\n",
      "Generator Step 9 average loss: 53.08906555175781\n",
      "Debug(train_generator) :-> Generator Training Ended\n",
      "--------------------------------------------------\n",
      "Debug(train_clone) :-> Starting Clone Model Training\n",
      "Clone Steps 0 average loss: 2.0337328910827637\n",
      "Clone Steps 0 Victim Classes Fired: [ 10.   0.   1.   1.   0.   2.   4.   0. 238.   0.])\n",
      "Clone Steps 0 Clone Classes Fired: [  5.   2.   4. 217.   0.   0.   0.   2.  26.   0.])\n",
      "Clone Steps 200 average loss: 1.465746521949768\n",
      "Clone Steps 200 Victim Classes Fired: [ 6122.   160.   290.  1520.    49. 11495.   967.  1661. 28425.   767.])\n",
      "Clone Steps 200 Clone Classes Fired: [1.4100e+02 3.0000e+00 6.8000e+01 2.2500e+02 0.0000e+00 2.4500e+02\n",
      " 2.1000e+01 7.0000e+00 5.0746e+04 0.0000e+00])\n",
      "Clone Steps 400 average loss: 1.4149314165115356\n",
      "Clone Steps 400 Victim Classes Fired: [12011.   336.   578.  3075.    91. 23045.  1980.  3300. 56656.  1584.])\n",
      "Clone Steps 400 Clone Classes Fired: [1.41000e+02 3.00000e+00 6.80000e+01 2.25000e+02 0.00000e+00 2.45000e+02\n",
      " 2.10000e+01 7.00000e+00 1.01946e+05 0.00000e+00])\n",
      "Debug(train_clone) :-> Clone Model Training Ended\n",
      "--------------------------------------------------\n",
      "[0.09]\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 10%|████████▎                                                                          | 1/10 [01:37<14:40, 97.83s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy of the network on the 10,000 test images: 10.03%\n",
      "\n",
      "Debug(train_generator) :-> Generating Images using Generator Model\n",
      "Debug(train_generator) :-> Starting Generator Training\n",
      "Generator Step 9 average loss: 83.86058807373047\n",
      "Debug(train_generator) :-> Generator Training Ended\n",
      "--------------------------------------------------\n",
      "Debug(train_clone) :-> Starting Clone Model Training\n",
      "Clone Steps 0 average loss: 0.5528713464736938\n",
      "Clone Steps 0 Victim Classes Fired: [ 37.   0.   0.   4.   1.  28.   4.   5. 176.   1.])\n",
      "Clone Steps 0 Clone Classes Fired: [  0.   0.   0.   0.   0.   0.   0.   0. 256.   0.])\n",
      "Clone Steps 200 average loss: 1.3807624578475952\n",
      "Clone Steps 200 Victim Classes Fired: [ 5780.   166.   342.  1490.    63. 11964.  1157.  1268. 28411.   815.])\n",
      "Clone Steps 200 Clone Classes Fired: [    0.     0.     0.     0.     0.     0.     0.     0. 51456.     0.])\n",
      "Clone Steps 400 average loss: 1.3626468777656555\n",
      "Clone Steps 400 Victim Classes Fired: [11461.   329.   636.  2847.   102. 23757.  2230.  2662. 57032.  1600.])\n",
      "Clone Steps 400 Clone Classes Fired: [0.00000e+00 0.00000e+00 0.00000e+00 0.00000e+00 0.00000e+00 0.00000e+00\n",
      " 0.00000e+00 0.00000e+00 1.02655e+05 1.00000e+00])\n",
      "Debug(train_clone) :-> Clone Model Training Ended\n",
      "--------------------------------------------------\n",
      "[0.08780243758165239]\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 20%|████████████████▌                                                                  | 2/10 [03:16<13:04, 98.12s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy of the network on the 10,000 test images: 9.89%\n",
      "\n",
      "Debug(train_generator) :-> Generating Images using Generator Model\n",
      "Debug(train_generator) :-> Starting Generator Training\n",
      "Generator Step 9 average loss: 87.55240631103516\n",
      "Debug(train_generator) :-> Generator Training Ended\n",
      "--------------------------------------------------\n",
      "Debug(train_clone) :-> Starting Clone Model Training\n",
      "Clone Steps 0 average loss: 0.40163886547088623\n",
      "Clone Steps 0 Victim Classes Fired: [ 18.   0.   4.   6.   0.  59.   1.   6. 156.   6.])\n",
      "Clone Steps 0 Clone Classes Fired: [  0.   0.   0.   0.   0.   0.   0.   0. 256.   0.])\n",
      "Clone Steps 200 average loss: 1.3041812578837078\n",
      "Clone Steps 200 Victim Classes Fired: [ 5483.   160.   365.  1356.    56. 12001.  1156.  1326. 28756.   797.])\n",
      "Clone Steps 200 Clone Classes Fired: [    0.     0.     0.     0.     0.     0.     0.     0. 51456.     0.])\n",
      "Clone Steps 400 average loss: 1.336810866991679\n",
      "Clone Steps 400 Victim Classes Fired: [11006.   313.   685.  2680.    98. 23738.  2332.  2642. 57613.  1549.])\n",
      "Clone Steps 400 Clone Classes Fired: [     0.      0.      0.      0.      0.      0.      0.      0. 102656.\n",
      "      0.])\n",
      "Debug(train_clone) :-> Clone Model Training Ended\n",
      "--------------------------------------------------\n",
      "[0.08142486304743513]\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 30%|████████████████████████▉                                                          | 3/10 [04:54<11:29, 98.43s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy of the network on the 10,000 test images: 9.89%\n",
      "\n",
      "Debug(train_generator) :-> Generating Images using Generator Model\n",
      "Debug(train_generator) :-> Starting Generator Training\n",
      "Generator Step 9 average loss: 86.54157257080078\n",
      "Debug(train_generator) :-> Generator Training Ended\n",
      "--------------------------------------------------\n",
      "Debug(train_clone) :-> Starting Clone Model Training\n",
      "Clone Steps 0 average loss: 0.34840601682662964\n",
      "Clone Steps 0 Victim Classes Fired: [ 45.   1.   4.   7.   0.  47.   7.   4. 138.   3.])\n",
      "Clone Steps 0 Clone Classes Fired: [  0.   0.   0.   0.   0.   0.   0.   0. 256.   0.])\n",
      "Clone Steps 200 average loss: 1.2570398151874542\n",
      "Clone Steps 200 Victim Classes Fired: [ 5495.   148.   355.  1328.    45. 11915.  1189.  1275. 28950.   756.])\n",
      "Clone Steps 200 Clone Classes Fired: [    0.     0.     0.     0.     0.     0.     0.     0. 51456.     0.])\n",
      "Clone Steps 400 average loss: 1.3899334967136383\n",
      "Clone Steps 400 Victim Classes Fired: [11039.   293.   725.  2660.    69. 23439.  2425.  2470. 58044.  1492.])\n",
      "Clone Steps 400 Clone Classes Fired: [     0.      0.      0.      0.      0.      0.      0.      0. 102656.\n",
      "      0.])\n",
      "Debug(train_clone) :-> Clone Model Training Ended\n",
      "--------------------------------------------------\n",
      "[0.07149155782793204]\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 40%|█████████████████████████████████▏                                                 | 4/10 [06:33<09:50, 98.35s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy of the network on the 10,000 test images: 9.89%\n",
      "\n",
      "Debug(train_generator) :-> Generating Images using Generator Model\n",
      "Debug(train_generator) :-> Starting Generator Training\n",
      "Generator Step 9 average loss: 86.73997497558594\n",
      "Debug(train_generator) :-> Generator Training Ended\n",
      "--------------------------------------------------\n",
      "Debug(train_clone) :-> Starting Clone Model Training\n",
      "Clone Steps 0 average loss: 0.23799195289611816\n",
      "Clone Steps 0 Victim Classes Fired: [  9.   0.   1.   4.   0.  83.   5.   6. 143.   5.])\n",
      "Clone Steps 0 Clone Classes Fired: [  0.   0.   0.   0.   0.   0.   0.   0. 256.   0.])\n",
      "Clone Steps 200 average loss: 1.2750438690185546\n",
      "Clone Steps 200 Victim Classes Fired: [ 5204.   146.   316.  1396.    44. 11727.  1170.  1201. 29562.   690.])\n",
      "Clone Steps 200 Clone Classes Fired: [    0.     0.     0.     0.     0.     0.     0.     0. 51456.     0.])\n",
      "Clone Steps 400 average loss: 1.2482617855072022\n",
      "Clone Steps 400 Victim Classes Fired: [10690.   296.   671.  2773.    84. 23287.  2366.  2446. 58627.  1416.])\n",
      "Clone Steps 400 Clone Classes Fired: [     0.      0.      0.      0.      0.      0.      0.      0. 102656.\n",
      "      0.])\n",
      "Debug(train_clone) :-> Clone Model Training Ended\n",
      "--------------------------------------------------\n",
      "[0.05897486304743513]\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 50%|█████████████████████████████████████████▌                                         | 5/10 [08:11<08:11, 98.23s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy of the network on the 10,000 test images: 9.89%\n",
      "\n",
      "Debug(train_generator) :-> Generating Images using Generator Model\n",
      "Debug(train_generator) :-> Starting Generator Training\n",
      "Generator Step 9 average loss: 85.73542022705078\n",
      "Debug(train_generator) :-> Generator Training Ended\n",
      "--------------------------------------------------\n",
      "Debug(train_clone) :-> Starting Clone Model Training\n",
      "Clone Steps 0 average loss: 0.21821218729019165\n",
      "Clone Steps 0 Victim Classes Fired: [ 32.   1.   3.   7.   0.  66.   1.   6. 136.   4.])\n",
      "Clone Steps 0 Clone Classes Fired: [  0.   0.   0.   0.   0.   0.   0.   0. 256.   0.])\n",
      "Clone Steps 200 average loss: 1.239438275496165\n",
      "Clone Steps 200 Victim Classes Fired: [ 5456.   179.   355.  1287.    48. 11807.  1204.  1186. 29187.   747.])\n",
      "Clone Steps 200 Clone Classes Fired: [    0.     0.     0.     0.     0.     0.     0.     0. 51456.     0.])\n",
      "Clone Steps 400 average loss: 1.2591044108072917\n",
      "Clone Steps 400 Victim Classes Fired: [10810.   348.   687.  2686.    93. 23375.  2395.  2377. 58434.  1451.])\n",
      "Clone Steps 400 Clone Classes Fired: [     0.      0.      0.      0.      0.      0.      0.      0. 102656.\n",
      "      0.])\n",
      "Debug(train_clone) :-> Clone Model Training Ended\n",
      "--------------------------------------------------\n",
      "[0.045099999999999994]\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 60%|█████████████████████████████████████████████████▊                                 | 6/10 [09:49<06:33, 98.41s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy of the network on the 10,000 test images: 9.89%\n",
      "\n",
      "Debug(train_generator) :-> Generating Images using Generator Model\n",
      "Debug(train_generator) :-> Starting Generator Training\n",
      "Generator Step 9 average loss: 87.09601593017578\n",
      "Debug(train_generator) :-> Generator Training Ended\n",
      "--------------------------------------------------\n",
      "Debug(train_clone) :-> Starting Clone Model Training\n",
      "Clone Steps 0 average loss: 0.1837878908429827\n",
      "Clone Steps 0 Victim Classes Fired: [ 13.   2.   1.  10.   1.  62.   7.   2. 151.   7.])\n",
      "Clone Steps 0 Clone Classes Fired: [  0.   0.   0.   0.   0.   0.   0.   0. 256.   0.])\n",
      "Clone Steps 200 average loss: 1.2723594222749983\n",
      "Clone Steps 200 Victim Classes Fired: [ 5546.   128.   342.  1382.    42. 11357.  1146.  1247. 29518.   748.])\n",
      "Clone Steps 200 Clone Classes Fired: [    0.     0.     0.     0.     0.     0.     0.     0. 51456.     0.])\n",
      "Clone Steps 400 average loss: 1.2969374316079276\n",
      "Clone Steps 400 Victim Classes Fired: [10987.   295.   670.  2748.    78. 22602.  2340.  2453. 58984.  1499.])\n",
      "Clone Steps 400 Clone Classes Fired: [     0.      0.      0.      0.      0.      0.      0.      0. 102656.\n",
      "      0.])\n",
      "Debug(train_clone) :-> Clone Model Training Ended\n",
      "--------------------------------------------------\n",
      "[0.03122513695256486]\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 70%|██████████████████████████████████████████████████████████                         | 7/10 [11:27<04:54, 98.25s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy of the network on the 10,000 test images: 9.89%\n",
      "\n",
      "Debug(train_generator) :-> Generating Images using Generator Model\n",
      "Debug(train_generator) :-> Starting Generator Training\n",
      "Generator Step 9 average loss: 88.62859344482422\n",
      "Debug(train_generator) :-> Generator Training Ended\n",
      "--------------------------------------------------\n",
      "Debug(train_clone) :-> Starting Clone Model Training\n",
      "Clone Steps 0 average loss: 0.16019199788570404\n",
      "Clone Steps 0 Victim Classes Fired: [ 24.   0.   0.   4.   1.  72.   3.   8. 138.   6.])\n",
      "Clone Steps 0 Clone Classes Fired: [  0.   0.   0.   0.   0.   0.   0.   0. 256.   0.])\n",
      "Clone Steps 200 average loss: 1.2990874201059341\n",
      "Clone Steps 200 Victim Classes Fired: [ 5554.   133.   334.  1340.    42. 11758.  1222.  1252. 29068.   753.])\n",
      "Clone Steps 200 Clone Classes Fired: [    0.     0.     0.     0.     0.     0.     0.     0. 51456.     0.])\n",
      "Clone Steps 400 average loss: 1.2383687496185303\n",
      "Clone Steps 400 Victim Classes Fired: [10746.   300.   653.  2690.    82. 23569.  2347.  2461. 58290.  1518.])\n",
      "Clone Steps 400 Clone Classes Fired: [     0.      0.      0.      0.      0.      0.      0.      0. 102656.\n",
      "      0.])\n",
      "Debug(train_clone) :-> Clone Model Training Ended\n",
      "--------------------------------------------------\n",
      "[0.01870844217206796]\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 80%|██████████████████████████████████████████████████████████████████▍                | 8/10 [13:05<03:16, 98.17s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy of the network on the 10,000 test images: 9.89%\n",
      "\n",
      "Debug(train_generator) :-> Generating Images using Generator Model\n",
      "Debug(train_generator) :-> Starting Generator Training\n",
      "Generator Step 9 average loss: 86.90513610839844\n",
      "Debug(train_generator) :-> Generator Training Ended\n",
      "--------------------------------------------------\n",
      "Debug(train_clone) :-> Starting Clone Model Training\n",
      "Clone Steps 0 average loss: 0.13998228973812527\n",
      "Clone Steps 0 Victim Classes Fired: [ 22.   1.   0.   4.   1.  68.   4.   4. 144.   8.])\n",
      "Clone Steps 0 Clone Classes Fired: [  0.   0.   0.   0.   0.   0.   0.   0. 256.   0.])\n",
      "Clone Steps 200 average loss: 1.271870454152425\n",
      "Clone Steps 200 Victim Classes Fired: [ 5557.   152.   368.  1500.    51. 11479.  1202.  1205. 29277.   665.])\n",
      "Clone Steps 200 Clone Classes Fired: [    0.     0.     0.     0.     0.     0.     0.     0. 51456.     0.])\n",
      "Clone Steps 400 average loss: 1.2563029395209417\n",
      "Clone Steps 400 Victim Classes Fired: [10781.   278.   726.  2844.    91. 23190.  2378.  2383. 58626.  1359.])\n",
      "Clone Steps 400 Clone Classes Fired: [     0.      0.      0.      0.      0.      0.      0.      0. 102656.\n",
      "      0.])\n",
      "Debug(train_clone) :-> Clone Model Training Ended\n",
      "--------------------------------------------------\n",
      "[0.008775136952564865]\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 90%|██████████████████████████████████████████████████████████████████████████▋        | 9/10 [14:44<01:38, 98.37s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy of the network on the 10,000 test images: 9.89%\n",
      "\n",
      "Debug(train_generator) :-> Generating Images using Generator Model\n",
      "Debug(train_generator) :-> Starting Generator Training\n",
      "Generator Step 9 average loss: 87.5033187866211\n",
      "Debug(train_generator) :-> Generator Training Ended\n",
      "--------------------------------------------------\n",
      "Debug(train_clone) :-> Starting Clone Model Training\n",
      "Clone Steps 0 average loss: 0.11843793392181397\n",
      "Clone Steps 0 Victim Classes Fired: [ 13.   1.   3.   8.   0.  65.   4.   6. 155.   1.])\n",
      "Clone Steps 0 Clone Classes Fired: [  0.   0.   0.   0.   0.   0.   0.   0. 256.   0.])\n",
      "Clone Steps 200 average loss: 1.2895360708236694\n",
      "Clone Steps 200 Victim Classes Fired: [ 5279.   159.   323.  1319.    48. 11674.  1151.  1142. 29590.   771.])\n",
      "Clone Steps 200 Clone Classes Fired: [    0.     0.     0.     0.     0.     0.     0.     0. 51456.     0.])\n",
      "Clone Steps 400 average loss: 1.2876222610473633\n",
      "Clone Steps 400 Victim Classes Fired: [10719.   298.   678.  2666.    91. 23316.  2405.  2338. 58668.  1477.])\n",
      "Clone Steps 400 Clone Classes Fired: [     0.      0.      0.      0.      0.      0.      0.      0. 102656.\n",
      "      0.])\n",
      "Debug(train_clone) :-> Clone Model Training Ended\n",
      "--------------------------------------------------\n",
      "[0.0023975624183476063]\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████████████████████████████████████████████████████████████████████████████| 10/10 [16:23<00:00, 98.35s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy of the network on the 10,000 test images: 9.89%\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    " for epoch in tqdm(range(1, args.epochs + 1)):\n",
    "     \n",
    "    generator_model = train_generator(args, generator_model, clone_model, epoch)\n",
    "    print('-'*50)\n",
    "    generator_model, clone_model, victim_model, optimizer_C = train_clone(args, generator_model, clone_model, victim_model, optimizer_C)\n",
    "    print('-'*50)\n",
    "    print(scheduler_lr.get_last_lr())\n",
    "    print()\n",
    "    evaluate(clone_model, testloader)\n",
    "    print()\n",
    "    scheduler_lr.step()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "609f975d-fe0d-4a5a-b24c-69f80960da1b",
   "metadata": {},
   "outputs": [],
   "source": [
    "z = torch.randn(100,256).to(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "32406030-c079-46ea-a595-43245c4dfa68",
   "metadata": {},
   "outputs": [],
   "source": [
    "with torch.no_grad():\n",
    "    fake = generator_model(z)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a62c4f2e-e121-47ec-96d6-b14fbdbc477f",
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.imshow(fake[52].cpu().numpy().transpose(1,2,0))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ced65c45-39ea-4818-8e2b-4c632407a7a3",
   "metadata": {},
   "outputs": [],
   "source": [
    "logit = clone_model(fake)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c71c2c74-34b6-4f23-86f6-775f95f6a356",
   "metadata": {},
   "outputs": [],
   "source": [
    "fake[0].max()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1c125b3c-52f2-4e5c-b174-f7fcef7af281",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "victim_model(fake).topk(1,1)[1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e8666447-cae7-4e30-940e-26865a654cee",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "torch22",
   "language": "python",
   "name": "torch22"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.14"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
